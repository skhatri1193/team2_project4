{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn as skl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and read csv\n",
    "heart_failure_df = pd.read_csv(\"/Users/siawashahmar/Desktop/Data Analytics Bootcamp/team2_project4/heart_failure_clinical_records_dataset.csv\")\n",
    "heart_failure_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns will be used as features\n",
    "No categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and target arrays\n",
    "\n",
    "y = heart_failure_df['DEATH_EVENT'].values\n",
    "X = heart_failure_df.drop(['DEATH_EVENT'], axis='columns').values\n",
    "\n",
    "# Split data into a training and testing dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a  StandardScaler Instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['relu','tanh','sigmoid'])\n",
    "\n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=10,\n",
    "        step=2), activation=activation, input_dim=12))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 6)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=10,\n",
    "            step=2),\n",
    "            activation=activation))\n",
    "\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./untitled_project/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Import the kerastuner library\n",
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=20,\n",
    "    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the kerastuner search for best hyperparameters\n",
    "tuner.search(X_train_scaled,y_train,epochs=20,validation_data=(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'first_units': 9,\n",
       " 'num_layers': 3,\n",
       " 'units_0': 5,\n",
       " 'units_1': 3,\n",
       " 'units_2': 5,\n",
       " 'units_3': 1,\n",
       " 'units_4': 1,\n",
       " 'units_5': 3,\n",
       " 'tuner/epochs': 20,\n",
       " 'tuner/initial_epoch': 7,\n",
       " 'tuner/bracket': 1,\n",
       " 'tuner/round': 1,\n",
       " 'tuner/trial_id': '0020'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best model hyperparameters\n",
    "best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "best_hyper.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 101ms/step - accuracy: 0.8133 - loss: 0.5097\n",
      "Loss: 0.5096867084503174, Accuracy: 0.8133333325386047\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model against full test data\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "model_loss, model_accuracy = best_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Optimization: First Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m117\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │           \u001b[38;5;34m360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m37\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> (2.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m514\u001b[0m (2.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> (2.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m514\u001b[0m (2.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model input features and hyperparameters\n",
    "\n",
    "input_feat = X_train.shape[1]\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#1st hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=9, input_dim=input_feat, activation=\"tanh\"))\n",
    "\n",
    "# 2nd hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=36, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"tanh\"))\n",
    "\n",
    "# Summary of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Create a call back to save model weights\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5900 - loss: 3.1556\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6653 - loss: 2.9722\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6706 - loss: 2.8860\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6620 - loss: 2.3134\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6618 - loss: 2.3157\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6835 - loss: 2.1488\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7145 - loss: 2.0393\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6976 - loss: 1.5126\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7414 - loss: 1.6357\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7303 - loss: 0.9952\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7070 - loss: 0.9068\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7487 - loss: 0.6304\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7145 - loss: 0.7475\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7437 - loss: 0.8864\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7579 - loss: 0.6968\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.7669\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7135 - loss: 0.5855\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7513 - loss: 0.5530  \n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7477 - loss: 0.6145\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7287 - loss: 0.6821\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7608 - loss: 0.5864\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7496 - loss: 0.5756\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7636 - loss: 0.6874\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7722 - loss: 0.5705  \n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7664 - loss: 0.5876\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7439 - loss: 0.5495\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7591 - loss: 0.5626\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7495 - loss: 0.6074\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7566 - loss: 0.4716  \n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: 0.6001\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7501 - loss: 0.6558\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7322 - loss: 0.6372\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7787 - loss: 0.5294\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7670 - loss: 0.5077\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7941 - loss: 0.4718\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7566 - loss: 0.4905\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7862 - loss: 0.5695\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7983 - loss: 0.4602\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7735 - loss: 0.4947\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7922 - loss: 0.5399\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8128 - loss: 0.5224\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7847 - loss: 0.4629\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7713 - loss: 0.5403\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7808 - loss: 0.6098\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7756 - loss: 0.5852\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8021 - loss: 0.4764\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7774 - loss: 0.5430\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8094 - loss: 0.5361  \n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7861 - loss: 0.5159\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.5034\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 61ms/step - accuracy: 0.7867 - loss: 0.7833\n",
      "Loss: 0.7832940220832825, Accurac: 0.7866666913032532\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m5,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,851</span> (22.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,851\u001b[0m (22.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,851</span> (22.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,851\u001b[0m (22.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model input features and hyperparameters\n",
    "\n",
    "input_feat = X_train.shape[1]\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#1st hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=50, input_dim=input_feat, activation=\"relu\"))\n",
    "\n",
    "# 2nd hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Summary of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6867 - loss: 0.6312\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6642 - loss: 0.6131\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.5211\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.5245\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8407 - loss: 0.4514\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8589 - loss: 0.4190\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8287 - loss: 0.4091\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8488 - loss: 0.3939\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8508 - loss: 0.3724\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.3443\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.3925\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.2946\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3336\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.2987\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8649 - loss: 0.3238\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8615 - loss: 0.3391\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8724 - loss: 0.2939\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3276\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.2591\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8806 - loss: 0.2651\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8762 - loss: 0.2546\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.2641\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8717 - loss: 0.2760\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.2517\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8945 - loss: 0.2442\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.2288\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2197\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.2335\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.2254  \n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.2166\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9283 - loss: 0.2067\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9271 - loss: 0.2344\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.1980\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.1923\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.1803\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.1815  \n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 0.1889\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.1730\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9560 - loss: 0.1727\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9537 - loss: 0.1708\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.1458\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.1603\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9435 - loss: 0.1513\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9412 - loss: 0.1644\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9723 - loss: 0.1329\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9767 - loss: 0.1163\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9626 - loss: 0.1470\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.1292\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.1352\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.1045\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Create a call back to save model weights\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 80ms/step - accuracy: 0.8400 - loss: 0.5401\n",
      "Loss: 0.5400630235671997, Accurac: 0.8399999737739563\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thrid Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m5,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,851</span> (22.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,851\u001b[0m (22.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,851</span> (22.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,851\u001b[0m (22.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model input features and hyperparameters\n",
    "\n",
    "input_feat = X_train.shape[1]\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#1st hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=50, input_dim=input_feat, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# 2nd hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Summary of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4540 - loss: 0.7329\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7155 - loss: 0.6180\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7761 - loss: 0.5563\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.5139\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.4834\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8341 - loss: 0.4359\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8155 - loss: 0.3935\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8580 - loss: 0.3890 \n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8467 - loss: 0.3938\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8654 - loss: 0.3685\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8774 - loss: 0.3475\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8787 - loss: 0.3298\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3499\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.3541\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 0.3416\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8728 - loss: 0.3216\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8508 - loss: 0.3203\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8863 - loss: 0.3002\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8752 - loss: 0.2893\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8786 - loss: 0.3045\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.2914\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8818 - loss: 0.2790\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.2596\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8609 - loss: 0.2672\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8732 - loss: 0.2826\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9048 - loss: 0.2468\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.2376\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8999 - loss: 0.2445\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.2013\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8977 - loss: 0.2368\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9235 - loss: 0.1985\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9149 - loss: 0.2186\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9255 - loss: 0.2168\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9064 - loss: 0.2415\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9219 - loss: 0.2160\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9402 - loss: 0.1988\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9249 - loss: 0.1847\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9486 - loss: 0.1733\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.1897\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9165 - loss: 0.1933\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9426 - loss: 0.1585\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.1686\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9361 - loss: 0.1733\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9563 - loss: 0.1512\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9402 - loss: 0.1776\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.1576\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9603 - loss: 0.1502\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.1560\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9442 - loss: 0.1357\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.1384\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Create a call back to save model weights\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 149ms/step - accuracy: 0.8133 - loss: 0.5301\n",
      "Loss: 0.5300652980804443, Accurac: 0.8133333325386047\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4th Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m5,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,951</span> (62.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,951\u001b[0m (62.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,951</span> (62.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,951\u001b[0m (62.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model input features and hyperparameters\n",
    "\n",
    "input_feat = X_train.shape[1]\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#1st hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=50, input_dim=input_feat,  activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# 2nd hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
    "\n",
    "# 3rd hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Summary of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6099 - loss: 0.6672\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7092 - loss: 0.5980\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6628 - loss: 0.5817 \n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7319 - loss: 0.5032\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8017 - loss: 0.4419\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8367 - loss: 0.4353\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.3958\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8607 - loss: 0.3385\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8565 - loss: 0.3320\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8434 - loss: 0.3483\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8665 - loss: 0.2970\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.2855\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8888 - loss: 0.2591\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8955 - loss: 0.2320\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8920 - loss: 0.2325\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8737 - loss: 0.2277\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.1791\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8898 - loss: 0.2000\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2100\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.1883\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9576 - loss: 0.1497\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9691 - loss: 0.1211\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9732 - loss: 0.1207\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9743 - loss: 0.1146\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9786 - loss: 0.1127\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9810 - loss: 0.0999\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9729 - loss: 0.1085 \n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0926\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0794\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0608\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9926 - loss: 0.0739\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0537\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0498\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0478\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0364\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0418\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0324\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0352\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0326\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0331\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0245\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0258\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0211\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0192\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0155\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0162\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0149\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0125\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0144\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0109\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Create a call back to save model weights\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 151ms/step - accuracy: 0.7600 - loss: 1.5107\n",
      "Loss: 1.5106961727142334, Accurac: 0.7599999904632568\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5th Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m117\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │           \u001b[38;5;34m360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m37\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> (2.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m514\u001b[0m (2.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> (2.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m514\u001b[0m (2.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model input features and hyperparameters\n",
    "\n",
    "input_feat = X_train.shape[1]\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#1st hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=9, input_dim=input_feat, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# 2nd hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=36, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Summary of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7050 - loss: 0.6285\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7218 - loss: 0.6276\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7465 - loss: 0.5846\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7639 - loss: 0.5503\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7525 - loss: 0.5600\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.5356\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7165 - loss: 0.5615\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7167 - loss: 0.5567\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7504 - loss: 0.5155\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7622 - loss: 0.5094\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7824 - loss: 0.4805\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8096 - loss: 0.4752\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7940 - loss: 0.4661\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8130 - loss: 0.4804\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.4760\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8185 - loss: 0.4655\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7836 - loss: 0.4819\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8481 - loss: 0.4342\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8122 - loss: 0.4737\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8506 - loss: 0.4247\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8339 - loss: 0.4409\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8329 - loss: 0.4434\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8460 - loss: 0.4076\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.4043\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8559 - loss: 0.3816\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8520 - loss: 0.3960\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.3834\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8564 - loss: 0.3724\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.4125\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.4045\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8288 - loss: 0.3687\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.3716\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8473 - loss: 0.3682\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8607 - loss: 0.3640\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8426 - loss: 0.3545\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8374 - loss: 0.3717\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.3382\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8614 - loss: 0.3433\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8382 - loss: 0.3622\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8786 - loss: 0.3186\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8510 - loss: 0.3668\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8662 - loss: 0.3584  \n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8796 - loss: 0.3281\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8735 - loss: 0.3567\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8984 - loss: 0.3088\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8790 - loss: 0.3228\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8889 - loss: 0.3255\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8908 - loss: 0.3314\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.3100 \n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.3377\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8918 - loss: 0.3071\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8817 - loss: 0.3211\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8797 - loss: 0.3176\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 0.3240\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8679 - loss: 0.3307\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8789 - loss: 0.3182\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8919 - loss: 0.3029\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8798 - loss: 0.3162\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.3053\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8785 - loss: 0.3168\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8931 - loss: 0.2982\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.2789\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8752 - loss: 0.3267\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8705 - loss: 0.3169\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.2699\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9198 - loss: 0.2555\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8945 - loss: 0.2836\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9026 - loss: 0.2601\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9185 - loss: 0.2603\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.2875\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8878 - loss: 0.2819\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3185\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8984 - loss: 0.2791\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.2656\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8794 - loss: 0.3109\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2546\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9217 - loss: 0.2443\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8815 - loss: 0.2989\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.3065\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8806 - loss: 0.3064\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9234 - loss: 0.2436\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9020 - loss: 0.2578\n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8957 - loss: 0.2592\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.2488\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8807 - loss: 0.2970\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8873 - loss: 0.2829\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.2438\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8856 - loss: 0.2698\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8782 - loss: 0.2799\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8903 - loss: 0.2578\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.2758\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8923 - loss: 0.2764\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2567\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8953 - loss: 0.2602\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2519\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9047 - loss: 0.2589\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8710 - loss: 0.2850\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8872 - loss: 0.2723\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8980 - loss: 0.2580\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8979 - loss: 0.2390\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Create a call back to save model weights\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 92ms/step - accuracy: 0.8400 - loss: 0.4351\n",
      "Loss: 0.4350535571575165, Accurac: 0.8399999737739563\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6th Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m117\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │           \u001b[38;5;34m360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m37\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> (2.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m514\u001b[0m (2.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> (2.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m514\u001b[0m (2.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model input features and hyperparameters\n",
    "\n",
    "input_feat = X_train.shape[1]\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#1st hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=9, input_dim=input_feat, activation=\"tanh\"))\n",
    "\n",
    "# 2nd hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=36, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Summary of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4631 - loss: 0.7095\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4991 - loss: 0.7015 \n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5990 - loss: 0.6732\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6672 - loss: 0.6431\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6722 - loss: 0.6320\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6960 - loss: 0.6197\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6965 - loss: 0.6156\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7292 - loss: 0.5937\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.5993\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7157 - loss: 0.5925\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7627 - loss: 0.5673\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7646 - loss: 0.5758\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7723 - loss: 0.5544\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7872 - loss: 0.5225\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7379 - loss: 0.5537\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7552 - loss: 0.5198\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7812 - loss: 0.5161\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8016 - loss: 0.5046\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.4733\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.4851\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8007 - loss: 0.4723 \n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7872 - loss: 0.4920\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8383 - loss: 0.4424\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.4884\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8200 - loss: 0.4554\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.4334\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8245 - loss: 0.4391\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.4192\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.4149\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8403 - loss: 0.4017\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8167 - loss: 0.4317\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8312 - loss: 0.4070\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8255 - loss: 0.4254\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8539 - loss: 0.3846\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8544 - loss: 0.3816\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: 0.3994\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.3896\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8639 - loss: 0.3597\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8603 - loss: 0.3566\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8668 - loss: 0.3371\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8862 - loss: 0.3145\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8490 - loss: 0.3587\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8678 - loss: 0.3300\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.3670\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8478 - loss: 0.3532\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8440 - loss: 0.3543\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8720 - loss: 0.3149\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3599\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8681 - loss: 0.3228\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8625 - loss: 0.3223\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8578 - loss: 0.3273\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8230 - loss: 0.3687\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8447 - loss: 0.3316\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8925 - loss: 0.2901\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.2741\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8561 - loss: 0.3207\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8510 - loss: 0.3522\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8631 - loss: 0.3150\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8785 - loss: 0.2927\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8765 - loss: 0.2848\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8701 - loss: 0.2983\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8978 - loss: 0.2626\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.2980\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.2727\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8799 - loss: 0.2838\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8703 - loss: 0.3036\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8628 - loss: 0.3034\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.3041\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8919 - loss: 0.2718\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.2826\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.2580\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.2664\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8825 - loss: 0.2619\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.2884\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8746 - loss: 0.2843\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 0.2751\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.2649\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2379\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.2852\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8739 - loss: 0.2778\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8920 - loss: 0.2571\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.2605  \n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.2579\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2575\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.2352\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8993 - loss: 0.2452\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9194 - loss: 0.2335\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.2341\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.2760\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.2505\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.2533\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9053 - loss: 0.2486\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9086 - loss: 0.2299\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.2301\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8892 - loss: 0.2585\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.2416\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8943 - loss: 0.2480\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.2443\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.2563\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.2065\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Create a call back to save model weights\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 57ms/step - accuracy: 0.8267 - loss: 0.4469\n",
      "Loss: 0.4468637704849243, Accurac: 0.8266666531562805\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of hidden layers resulted in a decrease of accuracy and increase of loss >1; suggest model may be too complex for data\n",
    "\n",
    "How to Address High Loss\n",
    "\n",
    "    Normalize/Standardize Data: Rescale your inputs and outputs to a range that aligns with your model's activation functions and loss functions.\n",
    "\n",
    "    Adjust the Model: Ensure the architecture is appropriate for the complexity of your data.\n",
    "\n",
    "    Tune Hyperparameters: Experiment with learning rate, regularization, and optimizer settings.\n",
    "\n",
    "    Inspect Data: Check for noisy, inconsistent, or outlier data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Architecture Details\n",
    "\n",
    "Input Layer Configuration\n",
    "\n",
    "Input dimension matches feature count\n",
    "First layer uses 50 neurons with LeakyReLU activation\n",
    "Uses negative slope (alpha) of 0.1 for LeakyReLU\n",
    "\n",
    "\n",
    "Hidden Layers\n",
    "\n",
    "First hidden layer: 50 neurons with LeakyReLU\n",
    "Second hidden layer: 100 neurons with ReLU\n",
    "Output layer: Single neuron with sigmoid activation\n",
    "\n",
    "\n",
    "Model Parameters\n",
    "\n",
    "Total params: 5,851\n",
    "Trainable params: 5,851\n",
    "\n",
    "\n",
    "\n",
    "Training Performance\n",
    "\n",
    "Used Early Stopping (patience=5)\n",
    "Trained for 50 epochs\n",
    "Accuracy progression:\n",
    "\n",
    "Started around 51-52% in first epoch\n",
    "Steadily improved to 96-97% in later epochs\n",
    "\n",
    "\n",
    "Final training accuracy: 95.66%\n",
    "Test set accuracy: 85.33%\n",
    "\n",
    "Key Observations\n",
    "\n",
    "Strong Performance\n",
    "\n",
    "High training accuracy (95.66%)\n",
    "Solid test accuracy (85.33%)\n",
    "Smooth learning curve\n",
    "\n",
    "\n",
    "Potential Overfitting Indicators\n",
    "\n",
    "Large gap between training (95.66%) and test (85.33%) accuracy\n",
    "Suggests model might be overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7th Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prevent Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m5,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,851</span> (22.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,851\u001b[0m (22.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,851</span> (22.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,851\u001b[0m (22.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "nn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, \n",
    "        input_dim=input_feat, \n",
    "        activation=tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        kernel_regularizer=l2(0.001)  # Add L2 regularization\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(0.3),  # Add dropout\n",
    "    \n",
    "    tf.keras.layers.Dense(100, \n",
    "        activation=\"relu\",\n",
    "        kernel_regularizer=l2(0.001)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3211 - loss: 0.9131\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5311 - loss: 0.7837\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6359 - loss: 0.7454\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6632 - loss: 0.7112\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.6530\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7617 - loss: 0.6014\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7504 - loss: 0.6299\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.6187\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7427 - loss: 0.5905\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7994 - loss: 0.5815\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7950 - loss: 0.5631\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.5238\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8123 - loss: 0.4977\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7833 - loss: 0.5043\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.4810\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7594 - loss: 0.5521\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7875 - loss: 0.4800\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8443 - loss: 0.4412\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8225 - loss: 0.4943\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.4596\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8382 - loss: 0.4368\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8617 - loss: 0.4274\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.4219\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8588 - loss: 0.3999\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8576 - loss: 0.4244\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8355 - loss: 0.4397\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4154\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8232 - loss: 0.4560\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8673 - loss: 0.4090\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8225 - loss: 0.4491\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8458 - loss: 0.4293\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8390 - loss: 0.4377\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.3602\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4334\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.4191\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4400\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8744 - loss: 0.3599\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8407 - loss: 0.4109\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8701 - loss: 0.3670\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8754 - loss: 0.3865\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8402 - loss: 0.4260\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.4206\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9018 - loss: 0.3242\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.3683\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8749 - loss: 0.3664\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 0.3548\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.4025\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8227 - loss: 0.4082\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8863 - loss: 0.3581\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8681 - loss: 0.3385\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.3509\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.3746\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9043 - loss: 0.3279\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8757 - loss: 0.3580\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.3594\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.3366\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8653 - loss: 0.3714\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9053 - loss: 0.3155\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.3064\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8820 - loss: 0.3406\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.3089\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.3247\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8529 - loss: 0.3851\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8616 - loss: 0.3601\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8783 - loss: 0.3236\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8691 - loss: 0.3356\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.3605\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8907 - loss: 0.3148\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8820 - loss: 0.3389\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8751 - loss: 0.3342\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.3617\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8839 - loss: 0.3429\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8694 - loss: 0.3506\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.2943\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9179 - loss: 0.3092\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8743 - loss: 0.3187\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8928 - loss: 0.3176\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8942 - loss: 0.3412\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.3575\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8792 - loss: 0.3287\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.3108\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.2968\n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.3191\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.2959\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8738 - loss: 0.3478\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3406\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8673 - loss: 0.3272\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.3123\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8789 - loss: 0.3310\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8781 - loss: 0.3165\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.3206\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9148 - loss: 0.2680\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2778\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8504 - loss: 0.3007\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.3067\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2948\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2601\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8969 - loss: 0.3252\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8517 - loss: 0.3095\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3293\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Create a call back to save model weights\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 63ms/step - accuracy: 0.8400 - loss: 0.5170\n",
      "Loss: 0.5169656276702881, Accurac: 0.8399999737739563\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8th Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.7666666507720947, 0.8500000238418579, 0.8166666626930237, 0.8500000238418579, 0.7966101765632629]\n",
      "Mean CV Score: 0.8159887075424195\n",
      "Standard Deviation: 0.032006848151582785\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import clone_model\n",
    "\n",
    "def create_model(input_feat):\n",
    "    nn = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(50, \n",
    "            input_dim=input_feat, \n",
    "            activation=tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(100, \n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return nn\n",
    "\n",
    "# Perform Cross-Validation\n",
    "def cross_validate_model(X, y, input_feat):\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    \n",
    "    for train_index, val_index in kfold.split(X, y):\n",
    "        # Split data\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        # Scale data (using the same scaler as before)\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        \n",
    "        # Create and train model\n",
    "        model = create_model(input_feat)\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # Fit model\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train, \n",
    "            validation_data=(X_val_scaled, y_val),\n",
    "            epochs=50, \n",
    "            batch_size=32,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0  # Suppress output\n",
    "        )\n",
    "        \n",
    "        # Evaluate model\n",
    "        val_loss, val_accuracy = model.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "        cv_scores.append(val_accuracy)\n",
    "    \n",
    "    return cv_scores\n",
    "\n",
    "# Perform cross-validation\n",
    "input_feat = X_train.shape[1]\n",
    "cv_results = cross_validate_model(X, y, input_feat)\n",
    "\n",
    "print(\"Cross-validation scores:\", cv_results)\n",
    "print(\"Mean CV Score:\", np.mean(cv_results))\n",
    "print(\"Standard Deviation:\", np.std(cv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation Analysis\n",
    "Consistent Performance:\n",
    "\n",
    "    Scores Scores range from 76.67% to 86.67%\n",
    "    Relatively low standard deviation (3.92%)\n",
    "    Indicates model's stability across different data splits\n",
    "\n",
    "Improvement Suggestions\n",
    "\n",
    "    The 3.92% standard deviation suggests some variability\n",
    "    Could potentially improve by:\n",
    "\n",
    "        Collecting more data\n",
    "        Feature engineering\n",
    "        Trying ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9th Attempt - Address the warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.3087 - loss: 0.9243 - val_accuracy: 0.4222 - val_loss: 0.8105\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5466 - loss: 0.7775 - val_accuracy: 0.5778 - val_loss: 0.7685\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6241 - loss: 0.7448 - val_accuracy: 0.6444 - val_loss: 0.7446\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7099 - loss: 0.6970 - val_accuracy: 0.6444 - val_loss: 0.7259\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7490 - loss: 0.6489 - val_accuracy: 0.6444 - val_loss: 0.7113\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7590 - loss: 0.6302 - val_accuracy: 0.6222 - val_loss: 0.6975\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7476 - loss: 0.6355 - val_accuracy: 0.6444 - val_loss: 0.6823\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7332 - loss: 0.6017 - val_accuracy: 0.6667 - val_loss: 0.6699\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8084 - loss: 0.5622 - val_accuracy: 0.6667 - val_loss: 0.6588\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7432 - loss: 0.5651 - val_accuracy: 0.6667 - val_loss: 0.6481\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8133 - loss: 0.5190 - val_accuracy: 0.6667 - val_loss: 0.6401\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8117 - loss: 0.5288 - val_accuracy: 0.6889 - val_loss: 0.6296\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7966 - loss: 0.5378 - val_accuracy: 0.6889 - val_loss: 0.6197\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7915 - loss: 0.5343 - val_accuracy: 0.7111 - val_loss: 0.6106\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8036 - loss: 0.4938 - val_accuracy: 0.7111 - val_loss: 0.6030\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7916 - loss: 0.5293 - val_accuracy: 0.7111 - val_loss: 0.5942\n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7933 - loss: 0.5193 - val_accuracy: 0.7333 - val_loss: 0.5870\n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9007 - loss: 0.3905 - val_accuracy: 0.7111 - val_loss: 0.5798\n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8596 - loss: 0.4525 - val_accuracy: 0.7333 - val_loss: 0.5765\n",
      "Epoch 20/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8257 - loss: 0.4664 - val_accuracy: 0.7333 - val_loss: 0.5757\n",
      "Epoch 21/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8533 - loss: 0.4382 - val_accuracy: 0.7333 - val_loss: 0.5762\n",
      "Epoch 22/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8506 - loss: 0.4366 - val_accuracy: 0.7333 - val_loss: 0.5733\n",
      "Epoch 23/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8363 - loss: 0.4608 - val_accuracy: 0.7333 - val_loss: 0.5702\n",
      "Epoch 24/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8383 - loss: 0.4190 - val_accuracy: 0.7333 - val_loss: 0.5670\n",
      "Epoch 25/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8625 - loss: 0.4143 - val_accuracy: 0.7111 - val_loss: 0.5646\n",
      "Epoch 26/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8797 - loss: 0.3908 - val_accuracy: 0.7111 - val_loss: 0.5641\n",
      "Epoch 27/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8544 - loss: 0.4195 - val_accuracy: 0.7111 - val_loss: 0.5650\n",
      "Epoch 28/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8571 - loss: 0.4273 - val_accuracy: 0.7111 - val_loss: 0.5673\n",
      "Epoch 29/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8893 - loss: 0.3649 - val_accuracy: 0.7111 - val_loss: 0.5679\n",
      "Epoch 30/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8372 - loss: 0.4280 - val_accuracy: 0.7333 - val_loss: 0.5701\n",
      "Epoch 31/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8434 - loss: 0.3830 - val_accuracy: 0.7556 - val_loss: 0.5695\n",
      "Epoch 32/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8978 - loss: 0.3476 - val_accuracy: 0.7778 - val_loss: 0.5709\n",
      "Epoch 33/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8461 - loss: 0.3890 - val_accuracy: 0.7778 - val_loss: 0.5718\n",
      "Epoch 34/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8521 - loss: 0.3881 - val_accuracy: 0.7778 - val_loss: 0.5722\n",
      "Epoch 35/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8221 - loss: 0.4207 - val_accuracy: 0.7778 - val_loss: 0.5705\n",
      "Epoch 36/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8198 - loss: 0.4203 - val_accuracy: 0.7556 - val_loss: 0.5673\n"
     ]
    }
   ],
   "source": [
    "# Define input features\n",
    "input_feat = X_train.shape[1]\n",
    "\n",
    "# Create model with recommended input layer\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_feat,)),\n",
    "    tf.keras.layers.Dense(50, \n",
    "        activation=tf.keras.layers.LeakyReLU(negative_slope=0.1),\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(100, \n",
    "        activation=\"relu\",\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Create early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    validation_split=0.2,\n",
    "    epochs=50, \n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 9ms/step - accuracy: 0.8400 - loss: 0.5170\n",
      "Loss: 0.5169656276702881, Accurac: 0.8399999737739563\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot of Model Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'history' is from your model.fit()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot of Model Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
