{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn as skl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and read csv\n",
    "heart_failure_df = pd.read_csv(\"/Users/siawashahmar/Desktop/Data Analytics Bootcamp/team2_project4/heart_failure_clinical_records_dataset.csv\")\n",
    "heart_failure_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns will be used as features\n",
    "No categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and target arrays\n",
    "\n",
    "y = heart_failure_df['DEATH_EVENT'].values\n",
    "X = heart_failure_df.drop(['DEATH_EVENT'], axis='columns').values\n",
    "\n",
    "# Split data into a training and testing dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a  StandardScaler Instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['relu','tanh','sigmoid'])\n",
    "\n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=10,\n",
    "        step=2), activation=activation, input_dim=12))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 6)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=10,\n",
    "            step=2),\n",
    "            activation=activation))\n",
    "\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./untitled_project/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Import the kerastuner library\n",
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=20,\n",
    "    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the kerastuner search for best hyperparameters\n",
    "tuner.search(X_train_scaled,y_train,epochs=20,validation_data=(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'first_units': 9,\n",
       " 'num_layers': 3,\n",
       " 'units_0': 5,\n",
       " 'units_1': 3,\n",
       " 'units_2': 5,\n",
       " 'units_3': 1,\n",
       " 'units_4': 1,\n",
       " 'units_5': 3,\n",
       " 'tuner/epochs': 20,\n",
       " 'tuner/initial_epoch': 7,\n",
       " 'tuner/bracket': 1,\n",
       " 'tuner/round': 1,\n",
       " 'tuner/trial_id': '0020'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best model hyperparameters\n",
    "best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "best_hyper.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 101ms/step - accuracy: 0.8133 - loss: 0.5097\n",
      "Loss: 0.5096867084503174, Accuracy: 0.8133333325386047\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model against full test data\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "model_loss, model_accuracy = best_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Optimization: First Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m117\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │           \u001b[38;5;34m360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m37\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> (2.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m514\u001b[0m (2.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> (2.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m514\u001b[0m (2.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model input features and hyperparameters\n",
    "\n",
    "input_feat = X_train.shape[1]\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#1st hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=9, input_dim=input_feat, activation=\"tanh\"))\n",
    "\n",
    "# 2nd hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=36, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"tanh\"))\n",
    "\n",
    "# Summary of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Create a call back to save model weights\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5900 - loss: 3.1556\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6653 - loss: 2.9722\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6706 - loss: 2.8860\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6620 - loss: 2.3134\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6618 - loss: 2.3157\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6835 - loss: 2.1488\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7145 - loss: 2.0393\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6976 - loss: 1.5126\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7414 - loss: 1.6357\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7303 - loss: 0.9952\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7070 - loss: 0.9068\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7487 - loss: 0.6304\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7145 - loss: 0.7475\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7437 - loss: 0.8864\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7579 - loss: 0.6968\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.7669\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7135 - loss: 0.5855\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7513 - loss: 0.5530  \n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7477 - loss: 0.6145\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7287 - loss: 0.6821\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7608 - loss: 0.5864\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7496 - loss: 0.5756\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7636 - loss: 0.6874\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7722 - loss: 0.5705  \n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7664 - loss: 0.5876\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7439 - loss: 0.5495\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7591 - loss: 0.5626\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7495 - loss: 0.6074\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7566 - loss: 0.4716  \n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: 0.6001\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7501 - loss: 0.6558\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7322 - loss: 0.6372\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7787 - loss: 0.5294\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7670 - loss: 0.5077\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7941 - loss: 0.4718\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7566 - loss: 0.4905\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7862 - loss: 0.5695\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7983 - loss: 0.4602\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7735 - loss: 0.4947\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7922 - loss: 0.5399\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8128 - loss: 0.5224\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7847 - loss: 0.4629\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7713 - loss: 0.5403\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7808 - loss: 0.6098\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7756 - loss: 0.5852\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8021 - loss: 0.4764\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7774 - loss: 0.5430\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8094 - loss: 0.5361  \n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7861 - loss: 0.5159\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.5034\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 61ms/step - accuracy: 0.7867 - loss: 0.7833\n",
      "Loss: 0.7832940220832825, Accurac: 0.7866666913032532\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m5,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,851</span> (22.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,851\u001b[0m (22.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,851</span> (22.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,851\u001b[0m (22.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model input features and hyperparameters\n",
    "\n",
    "input_feat = X_train.shape[1]\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#1st hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=50, input_dim=input_feat, activation=\"relu\"))\n",
    "\n",
    "# 2nd hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Summary of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6867 - loss: 0.6312\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6642 - loss: 0.6131\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.5211\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.5245\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8407 - loss: 0.4514\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8589 - loss: 0.4190\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8287 - loss: 0.4091\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8488 - loss: 0.3939\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8508 - loss: 0.3724\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.3443\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.3925\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.2946\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3336\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.2987\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8649 - loss: 0.3238\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8615 - loss: 0.3391\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8724 - loss: 0.2939\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3276\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.2591\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8806 - loss: 0.2651\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8762 - loss: 0.2546\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.2641\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8717 - loss: 0.2760\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.2517\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8945 - loss: 0.2442\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.2288\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2197\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.2335\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.2254  \n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.2166\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9283 - loss: 0.2067\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9271 - loss: 0.2344\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.1980\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.1923\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.1803\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.1815  \n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 0.1889\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.1730\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9560 - loss: 0.1727\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9537 - loss: 0.1708\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.1458\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.1603\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9435 - loss: 0.1513\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9412 - loss: 0.1644\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9723 - loss: 0.1329\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9767 - loss: 0.1163\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9626 - loss: 0.1470\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.1292\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.1352\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.1045\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Create a call back to save model weights\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 80ms/step - accuracy: 0.8400 - loss: 0.5401\n",
      "Loss: 0.5400630235671997, Accurac: 0.8399999737739563\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thrid Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m5,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,851</span> (22.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,851\u001b[0m (22.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,851</span> (22.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,851\u001b[0m (22.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model input features and hyperparameters\n",
    "\n",
    "input_feat = X_train.shape[1]\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#1st hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=50, input_dim=input_feat, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# 2nd hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Summary of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4540 - loss: 0.7329\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7155 - loss: 0.6180\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7761 - loss: 0.5563\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.5139\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.4834\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8341 - loss: 0.4359\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8155 - loss: 0.3935\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8580 - loss: 0.3890 \n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8467 - loss: 0.3938\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8654 - loss: 0.3685\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8774 - loss: 0.3475\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8787 - loss: 0.3298\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3499\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.3541\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 0.3416\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8728 - loss: 0.3216\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8508 - loss: 0.3203\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8863 - loss: 0.3002\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8752 - loss: 0.2893\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8786 - loss: 0.3045\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.2914\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8818 - loss: 0.2790\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.2596\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8609 - loss: 0.2672\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8732 - loss: 0.2826\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9048 - loss: 0.2468\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.2376\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8999 - loss: 0.2445\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.2013\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8977 - loss: 0.2368\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9235 - loss: 0.1985\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9149 - loss: 0.2186\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9255 - loss: 0.2168\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9064 - loss: 0.2415\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9219 - loss: 0.2160\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9402 - loss: 0.1988\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9249 - loss: 0.1847\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9486 - loss: 0.1733\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.1897\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9165 - loss: 0.1933\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9426 - loss: 0.1585\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.1686\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9361 - loss: 0.1733\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9563 - loss: 0.1512\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9402 - loss: 0.1776\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.1576\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9603 - loss: 0.1502\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.1560\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9442 - loss: 0.1357\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.1384\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Create a call back to save model weights\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 149ms/step - accuracy: 0.8133 - loss: 0.5301\n",
      "Loss: 0.5300652980804443, Accurac: 0.8133333325386047\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4th Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m5,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,951</span> (62.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,951\u001b[0m (62.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,951</span> (62.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,951\u001b[0m (62.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model input features and hyperparameters\n",
    "\n",
    "input_feat = X_train.shape[1]\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#1st hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=50, input_dim=input_feat,  activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# 2nd hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
    "\n",
    "# 3rd hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Summary of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6099 - loss: 0.6672\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7092 - loss: 0.5980\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6628 - loss: 0.5817 \n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7319 - loss: 0.5032\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8017 - loss: 0.4419\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8367 - loss: 0.4353\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.3958\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8607 - loss: 0.3385\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8565 - loss: 0.3320\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8434 - loss: 0.3483\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8665 - loss: 0.2970\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.2855\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8888 - loss: 0.2591\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8955 - loss: 0.2320\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8920 - loss: 0.2325\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8737 - loss: 0.2277\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.1791\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8898 - loss: 0.2000\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2100\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.1883\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9576 - loss: 0.1497\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9691 - loss: 0.1211\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9732 - loss: 0.1207\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9743 - loss: 0.1146\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9786 - loss: 0.1127\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9810 - loss: 0.0999\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9729 - loss: 0.1085 \n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0926\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0794\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0608\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9926 - loss: 0.0739\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0537\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0498\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0478\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0364\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0418\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0324\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0352\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0326\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0331\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0245\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0258\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0211\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0192\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0155\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0162\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0149\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0125\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0144\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0109\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Create a call back to save model weights\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 151ms/step - accuracy: 0.7600 - loss: 1.5107\n",
      "Loss: 1.5106961727142334, Accurac: 0.7599999904632568\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5th Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m117\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │           \u001b[38;5;34m360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m37\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> (2.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m514\u001b[0m (2.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> (2.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m514\u001b[0m (2.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model input features and hyperparameters\n",
    "\n",
    "input_feat = X_train.shape[1]\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#1st hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=9, input_dim=input_feat, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# 2nd hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=36, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Summary of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7050 - loss: 0.6285\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7218 - loss: 0.6276\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7465 - loss: 0.5846\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7639 - loss: 0.5503\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7525 - loss: 0.5600\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.5356\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7165 - loss: 0.5615\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7167 - loss: 0.5567\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7504 - loss: 0.5155\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7622 - loss: 0.5094\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7824 - loss: 0.4805\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8096 - loss: 0.4752\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7940 - loss: 0.4661\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8130 - loss: 0.4804\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.4760\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8185 - loss: 0.4655\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7836 - loss: 0.4819\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8481 - loss: 0.4342\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8122 - loss: 0.4737\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8506 - loss: 0.4247\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8339 - loss: 0.4409\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8329 - loss: 0.4434\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8460 - loss: 0.4076\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.4043\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8559 - loss: 0.3816\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8520 - loss: 0.3960\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.3834\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8564 - loss: 0.3724\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.4125\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.4045\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8288 - loss: 0.3687\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.3716\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8473 - loss: 0.3682\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8607 - loss: 0.3640\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8426 - loss: 0.3545\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8374 - loss: 0.3717\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.3382\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8614 - loss: 0.3433\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8382 - loss: 0.3622\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8786 - loss: 0.3186\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8510 - loss: 0.3668\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8662 - loss: 0.3584  \n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8796 - loss: 0.3281\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8735 - loss: 0.3567\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8984 - loss: 0.3088\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8790 - loss: 0.3228\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8889 - loss: 0.3255\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8908 - loss: 0.3314\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.3100 \n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.3377\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8918 - loss: 0.3071\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8817 - loss: 0.3211\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8797 - loss: 0.3176\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 0.3240\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8679 - loss: 0.3307\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8789 - loss: 0.3182\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8919 - loss: 0.3029\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8798 - loss: 0.3162\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.3053\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8785 - loss: 0.3168\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8931 - loss: 0.2982\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.2789\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8752 - loss: 0.3267\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8705 - loss: 0.3169\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.2699\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9198 - loss: 0.2555\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8945 - loss: 0.2836\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9026 - loss: 0.2601\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9185 - loss: 0.2603\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.2875\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8878 - loss: 0.2819\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3185\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8984 - loss: 0.2791\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.2656\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8794 - loss: 0.3109\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2546\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9217 - loss: 0.2443\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8815 - loss: 0.2989\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.3065\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8806 - loss: 0.3064\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9234 - loss: 0.2436\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9020 - loss: 0.2578\n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8957 - loss: 0.2592\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.2488\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8807 - loss: 0.2970\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8873 - loss: 0.2829\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.2438\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8856 - loss: 0.2698\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8782 - loss: 0.2799\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8903 - loss: 0.2578\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.2758\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8923 - loss: 0.2764\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2567\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8953 - loss: 0.2602\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2519\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9047 - loss: 0.2589\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8710 - loss: 0.2850\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8872 - loss: 0.2723\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8980 - loss: 0.2580\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8979 - loss: 0.2390\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Create a call back to save model weights\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 92ms/step - accuracy: 0.8400 - loss: 0.4351\n",
      "Loss: 0.4350535571575165, Accurac: 0.8399999737739563\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6th Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m117\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │           \u001b[38;5;34m360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m37\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> (2.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m514\u001b[0m (2.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> (2.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m514\u001b[0m (2.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model input features and hyperparameters\n",
    "\n",
    "input_feat = X_train.shape[1]\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "#1st hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=9, input_dim=input_feat, activation=\"tanh\"))\n",
    "\n",
    "# 2nd hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=36, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Summary of model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4631 - loss: 0.7095\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4991 - loss: 0.7015 \n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5990 - loss: 0.6732\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6672 - loss: 0.6431\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6722 - loss: 0.6320\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6960 - loss: 0.6197\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6965 - loss: 0.6156\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7292 - loss: 0.5937\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.5993\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7157 - loss: 0.5925\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7627 - loss: 0.5673\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7646 - loss: 0.5758\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7723 - loss: 0.5544\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7872 - loss: 0.5225\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7379 - loss: 0.5537\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7552 - loss: 0.5198\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7812 - loss: 0.5161\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8016 - loss: 0.5046\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.4733\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.4851\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8007 - loss: 0.4723 \n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7872 - loss: 0.4920\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8383 - loss: 0.4424\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.4884\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8200 - loss: 0.4554\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.4334\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8245 - loss: 0.4391\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.4192\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.4149\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8403 - loss: 0.4017\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8167 - loss: 0.4317\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8312 - loss: 0.4070\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8255 - loss: 0.4254\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8539 - loss: 0.3846\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8544 - loss: 0.3816\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: 0.3994\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.3896\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8639 - loss: 0.3597\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8603 - loss: 0.3566\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8668 - loss: 0.3371\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8862 - loss: 0.3145\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8490 - loss: 0.3587\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8678 - loss: 0.3300\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.3670\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8478 - loss: 0.3532\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8440 - loss: 0.3543\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8720 - loss: 0.3149\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3599\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8681 - loss: 0.3228\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8625 - loss: 0.3223\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8578 - loss: 0.3273\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8230 - loss: 0.3687\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8447 - loss: 0.3316\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8925 - loss: 0.2901\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.2741\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8561 - loss: 0.3207\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8510 - loss: 0.3522\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8631 - loss: 0.3150\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8785 - loss: 0.2927\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8765 - loss: 0.2848\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8701 - loss: 0.2983\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8978 - loss: 0.2626\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.2980\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.2727\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8799 - loss: 0.2838\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8703 - loss: 0.3036\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8628 - loss: 0.3034\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.3041\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8919 - loss: 0.2718\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.2826\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.2580\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.2664\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8825 - loss: 0.2619\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.2884\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8746 - loss: 0.2843\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 0.2751\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.2649\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2379\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.2852\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8739 - loss: 0.2778\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8920 - loss: 0.2571\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.2605  \n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.2579\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2575\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.2352\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8993 - loss: 0.2452\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9194 - loss: 0.2335\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.2341\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.2760\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.2505\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.2533\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9053 - loss: 0.2486\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9086 - loss: 0.2299\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.2301\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8892 - loss: 0.2585\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.2416\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8943 - loss: 0.2480\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.2443\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.2563\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.2065\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Create a call back to save model weights\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 57ms/step - accuracy: 0.8267 - loss: 0.4469\n",
      "Loss: 0.4468637704849243, Accurac: 0.8266666531562805\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of hidden layers resulted in a decrease of accuracy and increase of loss >1; suggest model may be too complex for data\n",
    "\n",
    "How to Address High Loss\n",
    "\n",
    "    Normalize/Standardize Data: Rescale your inputs and outputs to a range that aligns with your model's activation functions and loss functions.\n",
    "\n",
    "    Adjust the Model: Ensure the architecture is appropriate for the complexity of your data.\n",
    "\n",
    "    Tune Hyperparameters: Experiment with learning rate, regularization, and optimizer settings.\n",
    "\n",
    "    Inspect Data: Check for noisy, inconsistent, or outlier data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Architecture Details\n",
    "\n",
    "Input Layer Configuration\n",
    "\n",
    "Input dimension matches feature count\n",
    "First layer uses 50 neurons with LeakyReLU activation\n",
    "Uses negative slope (alpha) of 0.1 for LeakyReLU\n",
    "\n",
    "\n",
    "Hidden Layers\n",
    "\n",
    "First hidden layer: 50 neurons with LeakyReLU\n",
    "Second hidden layer: 100 neurons with ReLU\n",
    "Output layer: Single neuron with sigmoid activation\n",
    "\n",
    "\n",
    "Model Parameters\n",
    "\n",
    "Total params: 5,851\n",
    "Trainable params: 5,851\n",
    "\n",
    "\n",
    "\n",
    "Training Performance\n",
    "\n",
    "Used Early Stopping (patience=5)\n",
    "Trained for 50 epochs\n",
    "Accuracy progression:\n",
    "\n",
    "Started around 51-52% in first epoch\n",
    "Steadily improved to 96-97% in later epochs\n",
    "\n",
    "\n",
    "Final training accuracy: 95.66%\n",
    "Test set accuracy: 85.33%\n",
    "\n",
    "Key Observations\n",
    "\n",
    "Strong Performance\n",
    "\n",
    "High training accuracy (95.66%)\n",
    "Solid test accuracy (85.33%)\n",
    "Smooth learning curve\n",
    "\n",
    "\n",
    "Potential Overfitting Indicators\n",
    "\n",
    "Large gap between training (95.66%) and test (85.33%) accuracy\n",
    "Suggests model might be overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7th Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prevent Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m5,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,851</span> (22.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,851\u001b[0m (22.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,851</span> (22.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,851\u001b[0m (22.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "nn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, \n",
    "        input_dim=input_feat, \n",
    "        activation=tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "        kernel_regularizer=l2(0.001)  # Add L2 regularization\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(0.3),  # Add dropout\n",
    "    \n",
    "    tf.keras.layers.Dense(100, \n",
    "        activation=\"relu\",\n",
    "        kernel_regularizer=l2(0.001)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3211 - loss: 0.9131\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5311 - loss: 0.7837\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6359 - loss: 0.7454\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6632 - loss: 0.7112\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.6530\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7617 - loss: 0.6014\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7504 - loss: 0.6299\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.6187\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7427 - loss: 0.5905\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7994 - loss: 0.5815\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7950 - loss: 0.5631\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.5238\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8123 - loss: 0.4977\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7833 - loss: 0.5043\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.4810\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7594 - loss: 0.5521\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7875 - loss: 0.4800\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8443 - loss: 0.4412\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8225 - loss: 0.4943\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.4596\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8382 - loss: 0.4368\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8617 - loss: 0.4274\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.4219\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8588 - loss: 0.3999\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8576 - loss: 0.4244\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8355 - loss: 0.4397\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4154\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8232 - loss: 0.4560\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8673 - loss: 0.4090\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8225 - loss: 0.4491\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8458 - loss: 0.4293\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8390 - loss: 0.4377\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.3602\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.4334\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.4191\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.4400\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8744 - loss: 0.3599\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8407 - loss: 0.4109\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8701 - loss: 0.3670\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8754 - loss: 0.3865\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8402 - loss: 0.4260\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.4206\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9018 - loss: 0.3242\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.3683\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8749 - loss: 0.3664\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 0.3548\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.4025\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8227 - loss: 0.4082\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8863 - loss: 0.3581\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8681 - loss: 0.3385\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.3509\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.3746\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9043 - loss: 0.3279\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8757 - loss: 0.3580\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.3594\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.3366\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8653 - loss: 0.3714\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9053 - loss: 0.3155\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.3064\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8820 - loss: 0.3406\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.3089\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.3247\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8529 - loss: 0.3851\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8616 - loss: 0.3601\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8783 - loss: 0.3236\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8691 - loss: 0.3356\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.3605\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8907 - loss: 0.3148\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8820 - loss: 0.3389\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8751 - loss: 0.3342\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.3617\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8839 - loss: 0.3429\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8694 - loss: 0.3506\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.2943\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9179 - loss: 0.3092\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8743 - loss: 0.3187\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8928 - loss: 0.3176\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8942 - loss: 0.3412\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.3575\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8792 - loss: 0.3287\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.3108\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.2968\n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.3191\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.2959\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8738 - loss: 0.3478\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3406\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8673 - loss: 0.3272\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.3123\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8789 - loss: 0.3310\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8781 - loss: 0.3165\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.3206\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9148 - loss: 0.2680\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2778\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8504 - loss: 0.3007\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.3067\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2948\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2601\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8969 - loss: 0.3252\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8517 - loss: 0.3095\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3293\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#Create a call back to save model weights\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 63ms/step - accuracy: 0.8400 - loss: 0.5170\n",
      "Loss: 0.5169656276702881, Accurac: 0.8399999737739563\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8th Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.7666666507720947, 0.8500000238418579, 0.8166666626930237, 0.8500000238418579, 0.7966101765632629]\n",
      "Mean CV Score: 0.8159887075424195\n",
      "Standard Deviation: 0.032006848151582785\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import clone_model\n",
    "\n",
    "def create_model(input_feat):\n",
    "    nn = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(50, \n",
    "            input_dim=input_feat, \n",
    "            activation=tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(100, \n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return nn\n",
    "\n",
    "# Perform Cross-Validation\n",
    "def cross_validate_model(X, y, input_feat):\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    \n",
    "    for train_index, val_index in kfold.split(X, y):\n",
    "        # Split data\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        # Scale data (using the same scaler as before)\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        \n",
    "        # Create and train model\n",
    "        model = create_model(input_feat)\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # Fit model\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train, \n",
    "            validation_data=(X_val_scaled, y_val),\n",
    "            epochs=50, \n",
    "            batch_size=32,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0  # Suppress output\n",
    "        )\n",
    "        \n",
    "        # Evaluate model\n",
    "        val_loss, val_accuracy = model.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "        cv_scores.append(val_accuracy)\n",
    "    \n",
    "    return cv_scores\n",
    "\n",
    "# Perform cross-validation\n",
    "input_feat = X_train.shape[1]\n",
    "cv_results = cross_validate_model(X, y, input_feat)\n",
    "\n",
    "print(\"Cross-validation scores:\", cv_results)\n",
    "print(\"Mean CV Score:\", np.mean(cv_results))\n",
    "print(\"Standard Deviation:\", np.std(cv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation Analysis\n",
    "Consistent Performance:\n",
    "\n",
    "    Scores Scores range from 76.67% to 86.67%\n",
    "    Relatively low standard deviation (3.92%)\n",
    "    Indicates model's stability across different data splits\n",
    "\n",
    "Improvement Suggestions\n",
    "\n",
    "    The 3.92% standard deviation suggests some variability\n",
    "    Could potentially improve by:\n",
    "\n",
    "        Collecting more data\n",
    "        Feature engineering\n",
    "        Trying ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9th Attempt - Address the warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.4347 - loss: 0.8347 - val_accuracy: 0.5778 - val_loss: 0.7675\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5526 - loss: 0.7780 - val_accuracy: 0.6667 - val_loss: 0.7307\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6476 - loss: 0.7279 - val_accuracy: 0.6444 - val_loss: 0.7127\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7019 - loss: 0.6778 - val_accuracy: 0.6444 - val_loss: 0.7031\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7351 - loss: 0.5986 - val_accuracy: 0.6222 - val_loss: 0.6965\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8482 - loss: 0.5495 - val_accuracy: 0.6222 - val_loss: 0.6917\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7715 - loss: 0.5741 - val_accuracy: 0.6222 - val_loss: 0.6869\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8067 - loss: 0.5489 - val_accuracy: 0.6444 - val_loss: 0.6779\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7772 - loss: 0.5674 - val_accuracy: 0.6222 - val_loss: 0.6692\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8054 - loss: 0.5116 - val_accuracy: 0.6222 - val_loss: 0.6611\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7794 - loss: 0.5525 - val_accuracy: 0.6667 - val_loss: 0.6538\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7959 - loss: 0.5186 - val_accuracy: 0.6889 - val_loss: 0.6419\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8034 - loss: 0.4838 - val_accuracy: 0.7111 - val_loss: 0.6320\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7993 - loss: 0.5068 - val_accuracy: 0.7333 - val_loss: 0.6240\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8454 - loss: 0.4618 - val_accuracy: 0.7111 - val_loss: 0.6149\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8106 - loss: 0.4660 - val_accuracy: 0.7111 - val_loss: 0.6093\n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8490 - loss: 0.4586 - val_accuracy: 0.7111 - val_loss: 0.6049\n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8575 - loss: 0.4360 - val_accuracy: 0.7111 - val_loss: 0.6002\n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8580 - loss: 0.4316 - val_accuracy: 0.7111 - val_loss: 0.5950\n",
      "Epoch 20/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8516 - loss: 0.4260 - val_accuracy: 0.7111 - val_loss: 0.5921\n",
      "Epoch 21/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7992 - loss: 0.4999 - val_accuracy: 0.7333 - val_loss: 0.5880\n",
      "Epoch 22/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8680 - loss: 0.4123 - val_accuracy: 0.7111 - val_loss: 0.5878\n",
      "Epoch 23/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8562 - loss: 0.4302 - val_accuracy: 0.6889 - val_loss: 0.5886\n",
      "Epoch 24/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8392 - loss: 0.3977 - val_accuracy: 0.6889 - val_loss: 0.5893\n",
      "Epoch 25/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8726 - loss: 0.4134 - val_accuracy: 0.6889 - val_loss: 0.5892\n",
      "Epoch 26/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8451 - loss: 0.3942 - val_accuracy: 0.6889 - val_loss: 0.5897\n",
      "Epoch 27/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8556 - loss: 0.3969 - val_accuracy: 0.6889 - val_loss: 0.5897\n",
      "Epoch 28/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8482 - loss: 0.3835 - val_accuracy: 0.6889 - val_loss: 0.5891\n",
      "Epoch 29/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8357 - loss: 0.4424 - val_accuracy: 0.6889 - val_loss: 0.5901\n",
      "Epoch 30/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8433 - loss: 0.4384 - val_accuracy: 0.7111 - val_loss: 0.5899\n",
      "Epoch 31/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8345 - loss: 0.4063 - val_accuracy: 0.7111 - val_loss: 0.5875\n",
      "Epoch 32/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8307 - loss: 0.4225 - val_accuracy: 0.7111 - val_loss: 0.5864\n",
      "Epoch 33/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8495 - loss: 0.4060 - val_accuracy: 0.7111 - val_loss: 0.5867\n",
      "Epoch 34/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8565 - loss: 0.3639 - val_accuracy: 0.7111 - val_loss: 0.5845\n",
      "Epoch 35/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8514 - loss: 0.4097 - val_accuracy: 0.7111 - val_loss: 0.5869\n",
      "Epoch 36/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8557 - loss: 0.3796 - val_accuracy: 0.7111 - val_loss: 0.5869\n",
      "Epoch 37/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8705 - loss: 0.3608 - val_accuracy: 0.7111 - val_loss: 0.5853\n",
      "Epoch 38/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8795 - loss: 0.3476 - val_accuracy: 0.7111 - val_loss: 0.5855\n",
      "Epoch 39/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8682 - loss: 0.4111 - val_accuracy: 0.7111 - val_loss: 0.5832\n",
      "Epoch 40/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8530 - loss: 0.4126 - val_accuracy: 0.7111 - val_loss: 0.5805\n",
      "Epoch 41/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8649 - loss: 0.3748 - val_accuracy: 0.7111 - val_loss: 0.5807\n",
      "Epoch 42/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8457 - loss: 0.4104 - val_accuracy: 0.7111 - val_loss: 0.5795\n",
      "Epoch 43/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8448 - loss: 0.3954 - val_accuracy: 0.7111 - val_loss: 0.5804\n",
      "Epoch 44/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8581 - loss: 0.3631 - val_accuracy: 0.7111 - val_loss: 0.5813\n",
      "Epoch 45/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8789 - loss: 0.3298 - val_accuracy: 0.7111 - val_loss: 0.5824\n",
      "Epoch 46/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8729 - loss: 0.3502 - val_accuracy: 0.7111 - val_loss: 0.5813\n",
      "Epoch 47/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9092 - loss: 0.3124 - val_accuracy: 0.7111 - val_loss: 0.5788\n",
      "Epoch 48/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8808 - loss: 0.3273 - val_accuracy: 0.7111 - val_loss: 0.5779\n",
      "Epoch 49/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8450 - loss: 0.3849 - val_accuracy: 0.7333 - val_loss: 0.5797\n",
      "Epoch 50/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8403 - loss: 0.3726 - val_accuracy: 0.7111 - val_loss: 0.5824\n"
     ]
    }
   ],
   "source": [
    "# Define input features\n",
    "input_feat = X_train.shape[1]\n",
    "\n",
    "# Create model with recommended input layer\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_feat,)),\n",
    "    tf.keras.layers.Dense(50, \n",
    "        activation=tf.keras.layers.LeakyReLU(negative_slope=0.1),\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(100, \n",
    "        activation=\"relu\",\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Create early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    validation_split=0.2,\n",
    "    epochs=50, \n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - 13ms/step - accuracy: 0.8533 - loss: 0.4608\n",
      "Loss: 0.4607767164707184, Accurac: 0.8533333539962769\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accurac: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot of Model Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAHUCAYAAACeWef3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABqhUlEQVR4nO3dd3wUdf7H8dfspveQkEZCIPQWWuggIEjVE1FBRIoCCrZDz4b8bFiwi+XAUykWFEREPSnSuxy9hx4SIAkhgXTS5/fHZJeEFFI2mU3yeT4e80gyOzv73T1u3367oqqqihBCCGFFDHoXQAghhLiZhJMQQgirI+EkhBDC6kg4CSGEsDoSTkIIIayOhJMQQgirI+EkhBDC6kg4CSGEsDoSTkIIIayOhJOo8xYtWoSiKCiKwubNm4s8rqoqTZs2RVEU+vXrZ9HXVhSF119/vdzPO3/+PIqisGjRojJd9+GHH1asgELoRMJJiHyurq7Mnz+/yPktW7Zw9uxZXF1ddSiVEHWThJMQ+UaPHs3y5ctJTk4udH7+/Pn06NGDhg0b6lQyIeoeCSch8o0ZMwaAn376yXwuKSmJ5cuX88gjjxT7nKtXr/L444/ToEED7OzsCAkJYebMmWRmZha6Ljk5mSlTpuDl5YWLiwtDhgzh1KlTxd7z9OnTPPjgg/j4+GBvb0+rVq3497//baF3WbyoqCgeeuihQq/50UcfkZeXV+i6efPm0b59e1xcXHB1daVly5a8/PLL5sfT09N57rnnaNy4MQ4ODtSrV4+wsLBCn6kQZWGjdwGEsBZubm7cd999LFiwgMceewzQgspgMDB69GjmzJlT6PqMjAz69+/P2bNneeONNwgNDWXbtm3Mnj2bgwcPsnLlSkDrsxoxYgQ7d+7k1VdfpUuXLuzYsYOhQ4cWKcPx48fp2bMnDRs25KOPPsLPz4+//vqLp59+mvj4eF577TWLv+8rV67Qs2dPsrKyePPNN2nUqBF//vknzz33HGfPnmXu3LkALFmyhMcff5ynnnqKDz/8EIPBwJkzZzh+/Lj5Xs8++yzff/89b731Fh07diQtLY2jR4+SkJBg8XKLWk4Voo5buHChCqh79uxRN23apALq0aNHVVVV1S5duqgTJ05UVVVV27Rpo/bt29f8vC+//FIF1J9//rnQ/d577z0VUNeuXauqqqquXr1aBdRPP/200HVvv/22Cqivvfaa+dzgwYPVwMBANSkpqdC1Tz75pOrg4KBevXpVVVVVjYiIUAF14cKFpb4303UffPBBide89NJLKqD+73//K3R+2rRpqqIo6smTJ81l8PDwKPX12rZtq44YMaLUa4QoC2nWE6KAvn370qRJExYsWMCRI0fYs2dPiU16GzduxNnZmfvuu6/Q+YkTJwKwYcMGADZt2gTA2LFjC1334IMPFvo7IyODDRs2cM899+Dk5EROTo75GDZsGBkZGezatcsSb7PI+2jdujVdu3Yt8j5UVWXjxo0AdO3alcTERMaMGcPvv/9OfHx8kXt17dqV1atX89JLL7F582auX79u8fKKukHCSYgCFEXh4Ycf5ocffuDLL7+kefPm9OnTp9hrExIS8PPzQ1GUQud9fHywsbExN2UlJCRgY2ODl5dXoev8/PyK3C8nJ4fPP/8cW1vbQsewYcMAig2EykpISMDf37/I+YCAAPPjAOPGjWPBggVERkZy77334uPjQ7du3Vi3bp35OZ999hkvvvgiv/32G/3796devXqMGDGC06dPW7zconaTcBLiJhMnTiQ+Pp4vv/yShx9+uMTrvLy8uHz5MupNm0nHxcWRk5ODt7e3+bqcnJwi/S6xsbGF/vb09MRoNDJx4kT27NlT7GEKKUvy8vIiJiamyPno6GgA8/sAePjhh9m5cydJSUmsXLkSVVW58847iYyMBMDZ2Zk33niDEydOEBsby7x589i1axd33XWXxcstajcJJyFu0qBBA55//nnuuusuJkyYUOJ1AwYMIDU1ld9++63Q+e+++878OED//v0BWLx4caHrfvzxx0J/Ozk50b9/fw4cOEBoaChhYWFFjptrX5YwYMAAjh8/zv79+4u8D0VRzOUvyNnZmaFDhzJz5kyysrI4duxYkWt8fX2ZOHEiY8aM4eTJk6Snp1u87KL2ktF6QhTj3XffveU148eP59///jcTJkzg/PnztGvXju3bt/POO+8wbNgwBg4cCMCgQYO47bbbeOGFF0hLSyMsLIwdO3bw/fffF7nnp59+Su/evenTpw/Tpk2jUaNGpKSkcObMGf773/+a+3/K68iRI/zyyy9Fznfp0oVnnnmG7777juHDhzNr1iyCg4NZuXIlc+fOZdq0aTRv3hyAKVOm4OjoSK9evfD39yc2NpbZs2fj7u5Oly5dAOjWrRt33nknoaGheHp6Eh4ezvfff0+PHj1wcnKqUNlFHaXzgAwhdFdwtF5pbh6tp6qqmpCQoE6dOlX19/dXbWxs1ODgYHXGjBlqRkZGoesSExPVRx55RPXw8FCdnJzUO+64Qz1x4kSR0Xqqqo2we+SRR9QGDRqotra2av369dWePXuqb731VqFrKMdovZIO0/MjIyPVBx98UPXy8lJtbW3VFi1aqB988IGam5trvte3336r9u/fX/X19VXt7OzUgIAAddSoUerhw4fN17z00ktqWFiY6unpqdrb26shISHqM888o8bHx5daTiFupqjqTQ3mQgghhM6kz0kIIYTVkXASQghhdSSchBBCWB0JJyGEEFZHwkkIIYTVkXASQghhdercJNy8vDyio6NxdXUtsiaaEEKIqqWqKikpKQQEBGAwlFw/qnPhFB0dTVBQkN7FEEKIOu3ChQsEBgaW+HidCydXV1dA+2Dc3Nx0Lo0QQtQtycnJBAUFmb+LS1LnwsnUlOfm5ibhJIQQOrlVt4oMiBBCCGF1JJyEEEJYHQknIYQQVqfO9TkJIbThvDk5OeTm5updFFHLGI1GbGxsKj1VR8JJiDomKyuLmJgY2ZlWVBknJyf8/f2xs7Or8D0knISoQ/Ly8oiIiMBoNBIQEICdnZ1MRhcWo6oqWVlZXLlyhYiICJo1a1bqRNvSSDgJUYdkZWWRl5dHUFCQbJsuqoSjoyO2trZERkaSlZWFg4NDhe4jAyKEqIMq+l+zQpSFJf59yb9QIYQQVkfCSQghhNWRcBJC1Fn9+vVj+vTpZb7+/PnzKIrCwYMHq6xMQiPhJISweoqilHpMnDixQvf99ddfefPNN8t8fVBQEDExMbRt27ZCr1dWEoIyWk8IUQPExMSYf1+6dCmvvvoqJ0+eNJ9zdHQsdH12dja2tra3vG+9evXKVQ6j0Yifn1+5niMqRmpO5fTBXycY8NFmfj94Se+iCGERqqqSnpWjy6GqapnK6OfnZz7c3d1RFMX8d0ZGBh4eHvz888/069cPBwcHfvjhBxISEhgzZgyBgYE4OTnRrl07fvrpp0L3vblZr1GjRrzzzjs88sgjuLq60rBhQ7766ivz4zfXaDZv3oyiKGzYsIGwsDCcnJzo2bNnoeAEeOutt/Dx8cHV1ZXJkyfz0ksv0aFDhwr97wWQmZnJ008/jY+PDw4ODvTu3Zs9e/aYH7927Rpjx46lfv36ODo60qxZMxYuXAho0wmefPJJ/P39cXBwoFGjRsyePbvCZakqUnMqp4TULM5eSeN8vMyuF7XD9excWr/6ly6vfXzWYJzsLPM19OKLL/LRRx+xcOFC7O3tycjIoHPnzrz44ou4ubmxcuVKxo0bR0hICN26dSvxPh999BFvvvkmL7/8Mr/88gvTpk3jtttuo2XLliU+Z+bMmXz00UfUr1+fqVOn8sgjj7Bjxw4AFi9ezNtvv83cuXPp1asXS5Ys4aOPPqJx48YVfq8vvPACy5cv59tvvyU4OJj333+fwYMHc+bMGerVq8crr7zC8ePHWb16Nd7e3pw5c4br168D8Nlnn/HHH3/w888/07BhQy5cuMCFCxcqXJaqIuFUTv7uWvNBTNJ1nUsihCho+vTpjBw5stC55557zvz7U089xZo1a1i2bFmp4TRs2DAef/xxQAu8Tz75hM2bN5caTm+//TZ9+/YF4KWXXmL48OFkZGTg4ODA559/zqRJk3j44YcBePXVV1m7di2pqakVep9paWnMmzePRYsWMXToUAC+/vpr1q1bx/z583n++eeJioqiY8eOhIWFAVqN0CQqKopmzZrRu3dvFEUhODi4QuWoahJO5eTvoc12jk7K0LkkQliGo62R47MG6/balmL6IjbJzc3l3XffZenSpVy6dInMzEwyMzNxdnYu9T6hoaHm303Nh3FxcWV+jr+/PwBxcXE0bNiQkydPmsPOpGvXrmzcuLFM7+tmZ8+eJTs7m169epnP2dra0rVrV8LDwwGYNm0a9957L/v372fQoEGMGDGCnj17AjBx4kTuuOMOWrRowZAhQ7jzzjsZNGhQhcpSlSScyinAVHNKlJqTqB0URbFY05qebg6djz76iE8++YQ5c+bQrl07nJ2dmT59OllZWaXe5+aBFIqikJeXV+bnmNYqLPicm9cvLGtfW3FMzy3unqZzQ4cOJTIykpUrV7J+/XoGDBjAE088wYcffkinTp2IiIhg9erVrF+/nlGjRjFw4EB++eWXCpepKsiAiHIy1ZxipOYkhFXbtm0bd999Nw899BDt27cnJCSE06dPV3s5WrRowe7duwud27t3b4Xv17RpU+zs7Ni+fbv5XHZ2Nnv37qVVq1bmc/Xr12fixIn88MMPzJkzp9DADjc3N0aPHs3XX3/N0qVLWb58OVevXq1wmapCzf/PpWpmqjmlZuaQnJGNm8Oth6sKIapf06ZNWb58OTt37sTT05OPP/6Y2NjYQl/g1eGpp55iypQphIWF0bNnT5YuXcrhw4cJCQm55XNvHvUH0Lp1a6ZNm8bzzz9PvXr1aNiwIe+//z7p6elMmjQJ0Pq1OnfuTJs2bcjMzOTPP/80v+9PPvkEf39/OnTogMFgYNmyZfj5+eHh4WHR911ZEk7l5GhnxMPJlsT0bGISM3Dzk3ASwhq98sorREREMHjwYJycnHj00UcZMWIESUlJ1VqOsWPHcu7cOZ577jkyMjIYNWoUEydOLFKbKs4DDzxQ5FxERATvvvsueXl5jBs3jpSUFMLCwvjrr7/w9PQEwM7OjhkzZnD+/HkcHR3p06cPS5YsAcDFxYX33nuP06dPYzQa6dKlC6tWrbK6xYAVtTKNnzVQcnIy7u7uJCUl4ebmVqF7DP10G+ExySx8uAv9W/hYuIRCVJ2MjAwiIiJo3LhxhbcyEJV3xx134Ofnx/fff693UapEaf/OyvodLDWnCghwdyA8JpmYROl3EkKULj09nS+//JLBgwdjNBr56aefWL9+PevWrdO7aFZNwqkCbgyKkBF7QojSKYrCqlWreOutt8jMzKRFixYsX76cgQMH6l00qybhVAGmibjRUnMSQtyCo6Mj69ev17sYNY519YDVEAFScxJCiCol4VQBN5YwkpqTEEJUBQmnCggwN+tdr9RMbyGEEMWTcKoAX3d7ADJz8riWnq1zaYQQovaRcKoAexsj3i5aQEXLGntCCGFxEk4VFCBr7AkhRJWRcKogf3cZsSdETVPczrdz5swp9TmKovDbb79V+rUtdZ+6QsKpgmSukxDV56677ipx0urff/+Noijs37+/3Pfds2cPjz76aGWLV8jrr79e7BbsMTEx5s0Bq8qiRYusbgHXipJwqiCZ6yRE9Zk0aRIbN24kMjKyyGMLFiygQ4cOdOrUqdz3rV+/Pk5OTpYo4i35+flhb29fLa9VG0g4VZB5rpPUnERNp6qQlabPUcapGHfeeSc+Pj4sWrSo0Pn09HSWLl3KpEmTSEhIYMyYMQQGBuLk5ES7du346aefSr3vzc16p0+f5rbbbsPBwYHWrVsXu/7diy++SPPmzXFyciIkJIRXXnmF7Gxt1O6iRYt44403OHToEIqioCiKucw3N+sdOXKE22+/HUdHR7y8vHj00UcLbd0+ceJERowYwYcffoi/vz9eXl488cQT5teqiKioKO6++25cXFxwc3Nj1KhRXL582fz4oUOH6N+/P66urri5udG5c2fz3lORkZHcddddeHp64uzsTJs2bVi1alWFy3IrsnxRBQWYt2uXmpOo4bLT4Z0AfV775WiwK33bdAAbGxvGjx/PokWLePXVV807vi5btoysrCzGjh1Leno6nTt35sUXX8TNzY2VK1cybtw4QkJC6Nat2y1fIy8vj5EjR+Lt7c2uXbtITk4u1D9l4urqyqJFiwgICODIkSNMmTIFV1dXXnjhBUaPHs3Ro0dZs2aNeckid3f3IvdIT09nyJAhdO/enT179hAXF8fkyZN58sknCwXwpk2b8Pf3Z9OmTZw5c4bRo0fToUMHpkyZcsv3czNVVRkxYgTOzs5s2bKFnJwcHn/8cUaPHs3mzZsBbXuPjh07Mm/ePIxGIwcPHjTv8vvEE0+QlZXF1q1bcXZ25vjx47i4uJS7HGUl4VRBpprT5eQM8vJUDAblFs8QQlTGI488wgcffMDmzZvp378/oDXpjRw5Ek9PTzw9PXnuuefM1z/11FOsWbOGZcuWlSmc1q9fT3h4OOfPnycwMBCAd955p0g/0f/93/+Zf2/UqBH/+te/WLp0KS+88AKOjo64uLhgY2ODn59fia+1ePFirl+/znfffWfeXv6LL77grrvu4r333sPX1xcAT09PvvjiC4xGIy1btmT48OFs2LChQuG0fv16Dh8+TEREBEFBQQB8//33tGnThj179tClSxeioqJ4/vnnadmyJQDNmjUzPz8qKop7772Xdu3aAZRps8TKkHCqIB9XewwKZOeqxKdm4uMme+OIGsrWSavB6PXaZdSyZUt69uzJggUL6N+/P2fPnmXbtm2sXbsWgNzcXN59912WLl3KpUuXyMzMJDMz0/zlfyvh4eE0bNjQHEwAPXr0KHLdL7/8wpw5czhz5gypqank5OSUe2+48PBw2rdvX6hsvXr1Ii8vj5MnT5rDqU2bNhiNRvM1/v7+HDlypFyvVfA1g4KCzMEE2q66Hh4ehIeH06VLF5599lkmT57M999/z8CBA7n//vtp0qQJAE8//TTTpk1j7dq1DBw4kHvvvZfQ0NAKlaUspM+pgmyMBnzdTE170u8kajBF0ZrW9DiU8rU4TJo0ieXLl5OcnMzChQsJDg5mwIABAHz00Ud88sknvPDCC2zcuJGDBw8yePBgsrKyynTv4pYiU24q365du3jggQcYOnQof/75JwcOHGDmzJllfo2Cr3XzvYt7TVOTWsHH8vLyyvVat3rNgudff/11jh07xvDhw9m4cSOtW7dmxYoVAEyePJlz584xbtw4jhw5QlhYGJ9//nmFylIWEk6VYJ7rJKtECFEtRo0ahdFo5Mcff+Tbb7/l4YcfNn+xbtu2jbvvvpuHHnqI9u3bExISwunTp8t879atWxMVFUV09I1a5N9//13omh07dhAcHMzMmTMJCwujWbNmRUYQ2tnZkZube8vXOnjwIGlpaYXubTAYaN68eZnLXB6m93fhwgXzuePHj5OUlESrVq3M55o3b84zzzzD2rVrGTlyJAsXLjQ/FhQUxNSpU/n111/517/+xddff10lZQUrCKe5c+eat/Lt3Lkz27ZtK/X6xYsX0759e5ycnPD39+fhhx8mISGhmkpbmL9H/lwnqTkJUS1cXFwYPXo0L7/8MtHR0UycONH8WNOmTVm3bh07d+4kPDycxx57jNjY2DLfe+DAgbRo0YLx48dz6NAhtm3bxsyZMwtd07RpU6KioliyZAlnz57ls88+M9csTBo1akRERAQHDx4kPj6ezMzMIq81duxYHBwcmDBhAkePHmXTpk089dRTjBs3ztykV1G5ubkcPHiw0HH8+HEGDhxIaGgoY8eOZf/+/ezevZvx48fTt29fwsLCuH79Ok8++SSbN28mMjKSHTt2sGfPHnNwTZ8+nb/++ouIiAj279/Pxo0bC4WapekaTkuXLmX69OnMnDmTAwcO0KdPH4YOHUpUVFSx12/fvp3x48czadIkjh07xrJly9izZw+TJ0+u5pJrAqTmJES1mzRpEteuXWPgwIE0bNjQfP6VV16hU6dODB48mH79+uHn58eIESPKfF+DwcCKFSvIzMyka9euTJ48mbfffrvQNXfffTfPPPMMTz75JB06dGDnzp288sorha659957GTJkCP3796d+/frFDmd3cnLir7/+4urVq3Tp0oX77ruPAQMG8MUXX5TvwyhGamoqHTt2LHQMGzbMPJTd09OT2267jYEDBxISEsLSpUsBMBqNJCQkMH78eJo3b86oUaMYOnQob7zxBqCF3hNPPEGrVq0YMmQILVq0YO7cuZUub0kUVcc9H7p160anTp2YN2+e+VyrVq0YMWIEs2fPLnL9hx9+yLx58zh79qz53Oeff877779fqKpamuTkZNzd3UlKSip3J+bNFmyPYNafxxnezp9/jy3/BEAhqltGRgYRERHm1gohqkJp/87K+h2sW80pKyuLffv2MWjQoELnBw0axM6dO4t9Ts+ePbl48SKrVq1CVVUuX77ML7/8wvDhw0t8nczMTJKTkwsdliJznYQQomroFk7x8fHk5uYWaV/19fUtsZ24Z8+eLF68mNGjR2NnZ4efnx8eHh6ljhiZPXs27u7u5qPgMMrKklUihBCiaug+IOLmoY2lDbE8fvw4Tz/9NK+++ir79u1jzZo1REREMHXq1BLvP2PGDJKSksxHWZv/ysI/v+YUl5JBTm7FhncKIYQoSrdJuN7e3hiNxiK1pLi4uBJHq8yePZtevXrx/PPPAxAaGoqzszN9+vThrbfewt/fv8hz7O3tq2yxRW9ne2yNCtm5KpdTMmmQP3pPCCFE5ehWc7Kzs6Nz585FFlZct24dPXv2LPY56enpGAyFi2yaPa3HuA6DQcFPRuyJGkjHcVCiDrDEvy9dm/WeffZZvvnmGxYsWEB4eDjPPPMMUVFR5ma6GTNmMH78ePP1d911F7/++ivz5s3j3Llz7Nixg6effpquXbsSEKDPwpXmfZ1krpOoAUwrDqSnp+tcElGbmf593bzCRXnourbe6NGjSUhIYNasWcTExNC2bVtWrVpFcHAwoG3OVXDO08SJE0lJSeGLL77gX//6Fx4eHtx+++289957er0FmeskahSj0YiHhwdxcXGANt+mpD5eIcpLVVXS09OJi4vDw8Oj0LqA5aXrPCc9WHKeE8B7a04wb/NZJvZsxOv/aGOBEgpRtVRVJTY2lsTERL2LImopDw8P/Pz8iv0Pn7J+B8uq5JVkqjlFS81J1BCKouDv74+Pj0+lNq4Toji2traVqjGZSDhVknmuk/Q5iRrGaDRa5EtEiKqg+zynms401ylGVokQQgiLkXCqpID8mlN8ahaZOaUvky+EEKJsJJwqycPJFgdb7WOMlaY9IYSwCAmnSlIUxVx7ipY19oQQwiIknCzAvEqE9DsJIYRFSDhZgIzYE0IIy5JwsgDzvk4y10kIISxCwskCpOYkhBCWJeFkAf5ScxJCCIuScLKAAKk5CSGERUk4WYCp5pR0PZv0rBydSyOEEDWfhFN55eVBzCFIv2o+5eZgi4u9tkyhzHUSQojKk3Aqrx/vh//cBif+LHTaX+Y6CSGExUg4lVdAR+3nuS2FTvt75Pc7Sc1JCCEqTcKpvBr31X5GbIUC+zSa93WSmpMQQlSahFN5BXUFG0dIi4O4cPNp81wnqTkJIUSlSTiVl409NOyu/R5xo2nPPNdJak5CCFFpEk4VEZLftFeg30nmOgkhhOVIOFWEqd8pcgfkavOazDviJl5HLdAXJYQQovwknCrCvz04uENmMkQfACDQ0xFbo0JaVi4Xr0nTnhBCVIaEU0UYjNCoj/Z7xGYA7G2MtPRzA+DIpSSdCiaEELWDhFNFhfTTfhbod2oX6A7A4YsSTkIIURkSThVl6ne6sBuytWa80AamcErUqVBCCFE7SDhVlHczcPWH3EyI2gVAaKAHoDXr5eXJoAghhKgoCaeKUpQCq0VoTXvNfF2wtzGQkpFD5NV0HQsnhBA1m4RTZdw038nWaKB1gDYoQpr2hBCi4iScKsNUc4o5CNcTgRv9TkdkUIQQQlSYhFNluDcAr6ag5sH57QC0y+93OizDyYUQosIknCrrpn6n0Pzh5McuJZErgyKEEKJCJJwq66Z+pyb1XXCyM5KWlcu5K6k6FkwIIWouCafKatQHUCD+JCTHYDQotA2QybhCCFEZEk6V5VRPW2sPtA0IubFShCxjJIQQFSPhZAkhxfc7yXByIYSoGAknS2hcoN9JVWmXP5z8WHQyObl5OhZMCCFqJgknS2jYA4x2kHwRrp6jkZczrvY2ZObkcTpOBkUIIUR5SThZgp0TBHbVfj+3GYNBoa0sAiuEEBUm4WQpJfY7yaAIIYQoLwknSynY75SVXmiFciGEEOUj4WQpDTqDR0PISITd/zHXnMJjksnMydW3bEIIUcNIOFmK0Qb6z9R+3/4JgQ6ZeDjZkp2rcipWBkUIIUR5SDhZUrv7wacNZCSh7JhjHlJ++FKivuUSQogaRsLJkgxGGPCq9vv/vqRn/UxAts8QQojyknCytOaDtXlPORncee17AA5JOAkhRLlIOFmaosDA1wEIPL+cECWaU5dTyMiWQRFCCFFWEk5VoWF3aD4URc3lZYdfyM1TOR6TrHephBCixpBwqioDXgEUBqq7CFXOSr+TEEKUg4RTVfFtA+0fAOAFmyWyUoQQQpSDhFNV6jeDPIMtvY3HsD2/Se/SCCFEjSHhVJU8g8loPxGAsamLSMvI0rc8QghRQ0g4VTGngS+RhgPtDBHEbflK7+IIIUSNIOFU1Zy9Wev5IADBf78Ch5bqXCAhhLB+Ek7VILrdNH7MuR0DebDiMTj4k95FEkIIqybhVA26hngzM+cRflEGASr8Ng0O/qh3sYQQwmpJOFWD0EB3bG1seO76BJLaTkALqMfhwA96F00IIayShFM1sLcx0iHQA1BY0/Bf0PVRQIXfn4T93+lcOiGEsD66h9PcuXNp3LgxDg4OdO7cmW3btpV47cSJE1EUpcjRpk2baixxxXRp7AnA7vOJMPR96DYVUOGPp2DvAl3LJoQQ1kbXcFq6dCnTp09n5syZHDhwgD59+jB06FCioqKKvf7TTz8lJibGfFy4cIF69epx//33V3PJy69Lo3oA7D6foC0OO+Rd6DZNe/DPZ2D5ZLh+TccSCiGE9dA1nD7++GMmTZrE5MmTadWqFXPmzCEoKIh58+YVe727uzt+fn7mY+/evVy7do2HH364mktefp2DPTEocOHqdWKTMvIDajb0exkUIxxZBnN7wpn1ehdVCCF0p1s4ZWVlsW/fPgYNGlTo/KBBg9i5c2eZ7jF//nwGDhxIcHBwiddkZmaSnJxc6NCDq4MtrQPcANh9/qp2UlGg34swaS14NYWUaPjhXvjzWchK06WcQghhDXQLp/j4eHJzc/H19S103tfXl9jY2Fs+PyYmhtWrVzN58uRSr5s9ezbu7u7mIygoqFLlrgxT096eiKuFHwgMg8e25fdDAXvnw7xeEPW/ai6hEEJYB90HRCiKUuhvVVWLnCvOokWL8PDwYMSIEaVeN2PGDJKSkszHhQsXKlPcSulqCqfzV4s+aOcEQ9+D8b+DWyBci4CFQ+D3J+DquWouqRBC6Eu3cPL29sZoNBapJcXFxRWpTd1MVVUWLFjAuHHjsLOzK/Vae3t73NzcCh16CcsPp5OXU0hML2ER2JB+8PhOaP8gqHnaXKjPw+DXxyD+dPUVVgghdKRbONnZ2dG5c2fWrVtX6Py6devo2bNnqc/dsmULZ86cYdKkSVVZRIur72pPiLczqgp7z5cyMs/BHe6ZB5PWQdM7QM2Fw0vgiy7wyySIC6++QgshhA50bdZ79tln+eabb1iwYAHh4eE888wzREVFMXWq1vcyY8YMxo8fX+R58+fPp1u3brRt27a6i1xpXRuX0rR3s6Cu8NAvMGUTtBgGqHD0F5jbHX4eD5ePVW1hhRBCJzZ6vvjo0aNJSEhg1qxZxMTE0LZtW1atWmUefRcTE1NkzlNSUhLLly/n008/1aPIldalUT2W7LlwY8ReWTToBGN+gpjDsPUDCP8Djv+uHa3vhr4vajvvCiFELaGoqqrqXYjqlJycjLu7O0lJSbr0P124mk6f9zdhY1A48vpgHO2M5b/J5eOw9X04tuLGudYj8kOqtcXKKoQQllbW72DdR+vVNYGejvi5OZCTp3LgQgVXhPBtDfcvgml/a6EEcPw3mNcDfp4A1yItVFohhNCHhFM1UxSFLqZ+p4hKLlfk2xpGfQvTdmrNe6CF1DcDIfZo5e4thBA6knDSQddGpkVgEyxzQ982MOo7LaR820JaHCwaBhd2W+b+QghRzSScdNC1sRcA+yMTyc7Ns9yNfdvAxJUQ1A0ykuC7u+HsRsvdXwghqomEkw6a+bjg7mjL9excjkVbeK0/Rw8YtwKa3A7Z6fDjaDj+h2VfQwghqpiEkw4MBoUu+U17RdbZswQ7ZxizROuHys2CZRPgwGLLv44QQlQRCSed3NjfqQrCCcDGHu5bCB3Hacsg/f44/D23al5LCCEsTMJJJ10KrBSRl1dFU80MRvjH59DjSe3vv2bAhllQt6a2CSFqIAknnbQNcMfR1khiejZnrqRW3QspCgx6C25/Rft720fa1vC5OVX3mkIIUUkSTjqxszHQsaEHALurot+pIEWB256Duz4DxQAHvoefx0H29ap9XSGEqCAJJx11KW1/p6rQeQKM/gFsHODkKvj+HrheyYnAQghRBSScdGReobyqa04FtRyuDTW3d4eov2HhMEiOrr7XF0KIMpBw0lHHhh4oCkQnZRCfmll9LxzcEx5ZDS5+EHcc5g+CK6eq7/WFEOIWJJx05GRng7+bAwCRCenV++K+bWDSWvBqCkkXYP5AOLe5essghBAlkHDSWUMvJ0DbSqPaeQbDI39BYFdtuaMf7oW9C6u/HEIIcRMJJ501rKeFU5Qe4QTg7A0T/gvt7oe8HPhzOqyZAXm5+pRHCCGQcNKd7uEEYOsAI7+G/v+n/b1rLvw0BjIsvO6fEEKUkYSTzoKsIZxAmwvV93ltySMbBzj9FywYLBsXCiF0IeGkM1PNSZc+p+K0HQkPrwIXX20k39e3w7ktepdKCFHHSDjpzBROsckZZGRbST9Pg84wZSP4tYP0ePh+BGx5H/IsuPeUEEKUQsJJZ/Wc7XC2M6KqcCnRipYTcg+ER9ZCx4e0Vc03vQ2L74W0eL1LJoSoAyScdKYoivX0O93Mzgnu/jeMmAc2jtquul/2hsidepdMCFHLSThZAfOIveqeiFtWHR7Umvm8m0NKDCy6E7bPkWY+IUSVkXCyAlYxnPxWfFvDlE3QbhSoubD+NVjxmOwNJYSoEhJOViDYqwaEE4C9C4z8Cu76FAy2cORnbX8oIYSwMAknKxBkbcPJS6Mo0HkiDPtA+3vjW3Byja5FEkLUPhJOVqBgs55aU5rJwh6GsEmACssny6rmQgiLknCyAg08HVEUSM/KJSEtS+/ilN2Qd6FhT8hKgSVj4Hqi3iUSQtQSEk5WwN7GaN46w+r7nQqysYNR34FbICSc0WpQsmCsEMICJJysRI3qdyrIpT48sFibB3VmHWx8U+8SCSFqAQknK2H1c51KE9AB7v5C+337J3DkF12LI4So+SScrIQpnCJrWs3JpN190Ouf2u+/PwkX9uhbHiFEjSbhZCUa1pS5TqUZ8Bo0vQNyrmu76kYf0LtEQogaSsLJStTYPqeCDEYY9a02gi8zCb4bAbFH9C6VEKIGknCyEsHWuHVGRdg5w9ifIbALZCTCd3dDXLjepRJC1DASTlbCarfOqAh7Vxj7C/h3gPQE+PYfEH9a71IJIWoQCScrYdVbZ1SEoweMWwG+7SAtDr69CxLO6l0qIUQNIeFkRaxuy/bKcqoH43+H+q20rTa+/Qdci9S7VEKIGkDCyYrU6LlOJXH2ggl/gFczSL4IC4dC9EG9SyWEsHISTlakVgwnL46LD0z4r7ZZYfIlWDAEjv+ud6mEEFZMwsmK1Ko+p5u5+cOkddBkgDYP6ufxsPk92axQCFEsCScrUiO3zigPRw948Gfo/rj29+Z34JdHILuGj04UQlichJMVaeBRQ7fOKA+jDQyZDXd9BgYbOPar1g+VHK13yYQQVkTCyYo42Brxq4lbZ1RE5wnaSD7HetoyR1/1l9UkhBBmEk5WptYNJy9No94wZaM21Dw1FhYNhwu79S6VEMIKSDhZmVo5nLw09RrDpL8gqDtk5K/Hd26z3qUSQuhMwsnKNKzNI/ZK4uAO436FJrdDdhosvh9OrNK7VEIIHUk4WZlaO9fpVuycYcwSaHUX5GbB0ofg8DK9SyWE0ImEk5WpFVtnVJSNPdy3CNqPATUXfp0CexfoXSohhA4knKyMqVkvJjmDzJwavHVGRRlt4O650GUKoMKfz8DmdyGnlg6tF0IUS8LJyng52+GUv3XGxWt1dHKqwQDDPoDez2p/b54N83rAqbX6lksIUW0knKyMoih1c1DEzRQFBr4GI+aBc31IOAM/3q9t/37lpN6lE0JUMQknK1Sn+51u1uFBeGo/9PonGGzhzHqY2wNWvwjXr+ldOiFEFZFwskLBdW2u0604uMEds+CJ/0GL4dpgif99CZ91gi0fQPpVvUsohLAwCScrVGeHk9+KVxMY8yOM+01bVeL6Vdj0FnzSBlY9D1cj9C6hEMJCJJysUK3eOsMSmvSHqdth5Dfg1w6y02H3V/B5J/h5Alzap3cJhRCVJOFkhQqur1crt86wBKMNhN4Pj23TFpBtMgDUPDj+G3x9Oyy6EyK2yn5RQtRQuofT3Llzady4MQ4ODnTu3Jlt27aVen1mZiYzZ84kODgYe3t7mjRpwoIFtWuipmnrjLTavHWGpSgKhPTTlj+aukObwGuwgfPb4Nu7YOEwOLtJQkqIGkbXcFq6dCnTp09n5syZHDhwgD59+jB06FCioqJKfM6oUaPYsGED8+fP5+TJk/z000+0bNmyGktd9erU1hmW5NcW7vkS/nkIuj4KRnuI2gnfj4AFg+HMBgkpIWoIRa1Au9GFCxdQFIXAwEAAdu/ezY8//kjr1q159NFHy3yfbt260alTJ+bNm2c+16pVK0aMGMHs2bOLXL9mzRoeeOABzp07R7169cpbbACSk5Nxd3cnKSkJNze3Ct2jOoz6z9/sjrjKpw904O4ODfQuTs2UHA07PoV9iyAnQzsX2AX6z9T6rYQQ1a6s38EVqjk9+OCDbNq0CYDY2FjuuOMOdu/ezcsvv8ysWbPKdI+srCz27dvHoEGDCp0fNGgQO3fuLPY5f/zxB2FhYbz//vs0aNCA5s2b89xzz3H9eskrKWRmZpKcnFzoqAnq3NYZVcEtAIa+p9Wkuj8BNo5wcY9Wk/rubri0X+8SCiFKUKFwOnr0KF27dgXg559/pm3btuzcuZMff/yRRYsWleke8fHx5Obm4uvrW+i8r68vsbGxxT7n3LlzbN++naNHj7JixQrmzJnDL7/8whNPPFHi68yePRt3d3fzERQUVLY3qbPG3s4A7IpI0LkktYCrHwx5B6Yfhm7TwGin7Rn1dX/4eTzEn9a7hEKIm1QonLKzs7G3twdg/fr1/OMf/wCgZcuWxMTElOteiqIU+ltV1SLnTPLy8lAUhcWLF9O1a1eGDRvGxx9/zKJFi0qsPc2YMYOkpCTzceHChXKVTy93dwjAoMCOMwmEx9SM2p7Vc/GBoe/Ck3uh/YOAAsd/h393gz+egsSa8W9DiLqgQuHUpk0bvvzyS7Zt28a6desYMmQIANHR0Xh5eZXpHt7e3hiNxiK1pLi4uCK1KRN/f38aNGiAu7u7+VyrVq1QVZWLFy8W+xx7e3vc3NwKHTVBoKcTQ9v5AzB/u0wutSjPYLhnHkzbCS2GaStO7P8O5rSDrwfA1g/h8jEZPCGEjioUTu+99x7/+c9/6NevH2PGjKF9+/aA1idkau67FTs7Ozp37sy6desKnV+3bh09e/Ys9jm9evUiOjqa1NRU87lTp05hMBjMgzNqk8m9GwPw+8FLxCVn6FyaWsi3NYz5CR5ZC436ACpc2gsb34R5PeHTUFj1gjYUPTdH79IKUadUaLQeQG5uLsnJyXh6eprPnT9/HicnJ3x8fMp0j6VLlzJu3Di+/PJLevTowVdffcXXX3/NsWPHCA4OZsaMGVy6dInvvvsOgNTUVFq1akX37t154403iI+PZ/LkyfTt25evv/66TK9ZU0brmdw7byf7Iq/x1O1N+degFnoXp3ZLjoFTa+DkaojYcmOEH4BbIHR5BDpNBOeytQ4IIYoq63ewTUVufv36dVRVNQdTZGQkK1asoFWrVgwePLjM9xk9ejQJCQnMmjWLmJgY2rZty6pVqwgODgYgJiam0JwnFxcX1q1bx1NPPUVYWBheXl6MGjWKt956qyJvo0aY3Lsx+yKv8cOuSB7v1xRHO6PeRaq93Pwh7GHtyEqDc1vg5Co4sRKSL8KGWbD5PWh3H3SdAgEdK/d6qgoZSZCeoC1em56grXJhsAGDMf9n/oEKWamQmar9zEqDzBTtZ162di9V1a5TVe0+ikFbNNfBvfBh7wbZ1yElGlJiISUm/2cspMVrr2e01QaOmH/agXsgBPeERr21/jshqlCFak6DBg1i5MiRTJ06lcTERFq2bImtrS3x8fF8/PHHTJs2rSrKahE1reaUm6fS78NNXLh6nbfvacvYbsF6F6nuyc6AYytg938g+sCN84Fdoe1IsHUq8EVuq23tYbApEDzx2s+0+BshZDrUGrrbsVczaNQLgntDcA9wa6Ct1iHELZT1O7hC4eTt7c2WLVto06YN33zzDZ9//jkHDhxg+fLlvPrqq4SHh1eq8FWppoUTwILtEcz68zgh9Z1Z/0xfDAb5EtCFqsLFvVpIHftNq7FYgp0rONXTDoMN5OXkH7k3fldVsHMBexewc77xu62zFoiKIT8clBu/5+VqtauMpKKHrSO4+mvD7N0CtJ+u/uDkpdW6crMhNyv/yIbcTIgLh/M74PJR4KavDaO9dh+3BtpP9wba73YuWvNoTuaNn7mZ2nvyaQMNu4NHw5KDTVW1of7nt2mfvamp1Xx9/k97F/BuAT4ttRXrXf0kLK1UlTbrpaen4+rqCsDatWsZOXIkBoOB7t27ExkZWbESixKN6hLEJ+tOce5KGptPxXF7y+JHM4oqpigQ1EU7Br2tjfCLPaQNlsjN0sLK/HsO2LtqX/bO3uDknf+7l/bT9LdTPbCx1/udlc/1axD5N0TugPPbIfawFjjXIrSjvNwaQMMeWlAF9wQbB23R3vPbtSO1+HmPpXJw10KqfnNt8rU5ZAsEro09BHXTXtO3jdaUKqxGhWpOoaGhTJ48mXvuuYe2bduyZs0aevTowb59+xg+fHiJk2itQU2sOQG8syqcr7aeo2cTL36c0l3v4ghxQ06W1m+VHA3Jl7QjKf9n9nWtlmZjr9WubOy18FFzta1NYg5pQV4aoz0EdYXgXlqYm7+yCnx1pSfAlRMQdwKunit/c6m9+41wDO4FAR20GqmwuCpt1vvll1948MEHyc3N5fbbbzcPB589ezZbt25l9erVFS95Faup4XQp8Tq3vb+J3DyVlU/3pk2A+62fJIS1y0rTmuuidmmL9F7Yo9VAA7tow/sb9dZ+t3Uo+z1zMrWmwCsntJ9qbtHBHUZbrQ8w6m+I+h9kpRS+h70bhPTVtmJpOkBreqxuqqqFbtJF7Ui+pP1UFHANKNyM6uJT9TW/jCRtZZXT67Tw7jK5Qrep0nACbU29mJgY2rdvj8GgTZfavXs3bm5uVr1KeE0NJ4CnfjrAfw9FM7JTAz4e1UHv4ghhebk5Wp+XjV31vublIxC5M//YoTVdFuTdQgupoG7a36a+s4J9aY4e4NkIPBqBR1DJzbXZGZB6GVLjtJ9pcZB6Jf9nHKRd0c4nRxeezlAaxagFVVBXLVRD+lU+UFUVYo/AmXVwej1c+N+NGmlQd5j0V4VuW+XhZHLx4kUURaFBg5qxcnZNDqeDFxIZ8e8d2BoVtr94O75u5fivSSFE2eTlQsxBbYuVMxvg4m4tMMtF0cLCMxic62s1oNQ4rf8sI6l8t3Lx1e7l3kCbb6co+c2n0dqRElt8M6ZnYy2kQvpCgzCtdlVSYKqqds/Lx7RAunxU61e8ub/Pqxk0uwOaDarwyv5VGk55eXm89dZbfPTRR+bVGlxdXfnXv/7FzJkzzTUpa1STwwng/i93suf8NZ7o34TnB1tvDVWIWuP6NW3O25n1EHdcaxY09Z2Z+tKMdloAJUbCtfOQfYvdBIz2Wui41AdnnwI/fbQwc/G50WR3qwEzebla8CWc0UY1ntusNZUWF1gO7trrONfXXtPBHRLOaWGUkVj0elsnaNwXmg2EpgO1mmElVWk4zZgxg/nz5/PGG2/Qq1cvVFVlx44dvP7660yZMoW33367UoWvSjU9nNYcjWXqD/twc7Dhq/FhdA+R1QqEsCqqqvVnmYIq7Yo2OtPVNz+QfMDBo2qHumcka02U5zZrq53En7r1wBPFCN7NtU07fdtqk8wbdrf4aNIqDaeAgAC+/PJL82rkJr///juPP/44ly5dKn+Jq0lND6fcPJXhn23jRKzWgTumaxAvDW2Fu6OMLBJClEBVtRpg2pX8fq38fq7r17S+Kb+2UL9ltUxrqNJwcnBw4PDhwzRv3rzQ+ZMnT9KhQ4dSN//TW00PJ4Ck69m8u/oEP+3WlnbycbVn1t1tGNLWX+eSCSFE6ap0J9z27dvzxRdfFDn/xRdfEBoaWpFbinJwd7Rl9sh2LH20OyHezsSlZDL1h/08+t1eYpNk9XIhRM1XoZrTli1bGD58OA0bNqRHjx4oisLOnTu5cOECq1atok+fPlVRVouoDTWngjKyc/n3pjPM23yWnDwVV3sbPn+wI/1ayMKcQgjrU6U1p759+3Lq1CnuueceEhMTuXr1KiNHjuTYsWMsXLiwwoUW5edga+Rfg1rw59O9aR/kQUpmDv/321Fycss79FUIIaxHpec5FXTo0CE6depEbq71rrRc22pOBV3PyqXXexu5mpbFpw904O4ONWPumRCi7qjSmpOwTo52Rh7u2QiAeZvPYsH/7hBCiGol4VTLjO/RCGc7IydiU9h88orexRFCiAqRcKpl3J1sGdtd25Bw3uazOpdGCCEqplz7OY0cObLUxxMTEytTFmEhk3o3ZtGO8+w+f5W9568S1qie3kUSQohyKVc4ubuXvk2Du7s748ePr1SBROX5ujkwslMDluy5wJdbzvKNhJMQooYpVzjJMPGa49HbQli69wLrw+M4GZtCCz9XvYskhBBlJn1OtVRIfReGtvUD4D9bpe9JCFGzSDjVYlP7NgHgj4PRXLx2iyX8hRDCikg41WKhgR70bupNTp7KN9si9C6OEEKUmYRTLTetn1Z7WrIniqtpWTqXRgghykbCqZbr2cSL0EB3MrLzWLTzvN7FEUKIMpFwquUURWFaft/TtzvPcyw6SecSCSHErUk41QGD2vjRwteVpOvZ/OOLHbyzKpz0rFts2SyEEDqScKoDjAaF7yd3ZXioP7l5Kl9tPccdH29l04k4vYsmhBDFknCqI3xcHfj3g51YOLELDTwcuZR4nYcX7eGJxfu5nCy75wohrIuEUx3Tv6UP6569jcduC8FoUFh5JIaBH21h80mpRQkhrIeEUx3kZGfDjGGt+OPJXrQPdCclM4f31pzUu1hCCGEm4VSHtQlw5+vxYQCciE0mOSNb5xIJIYRGwqmO83FzINjLCVWF/ZHX9C6OEEIAEk4CCAvWttTYe17CSQhhHSScBF0aeQKw5/xVnUsihBAaCSdh3in34IVEsnLydC6NEEJIOAmgSX1nPJ1syczJ46gsbySEsAISTgJFUcy1p73StCeEsAISTgIo2O8kgyKEEPqTcBIAhWpOqqrqXBohRF0n4SQAaBvgjr2NgWvp2Zy9kqZ3cYQQdZyEkwDAzsZAhyAPQPqdhBD6k3ASZl3ym/ak30kIoTcJJ2EWlj8oYm+k1JyEEPqScBJmnYI9URSITEgnTvZ4EkLoSMJJmLk52NLSzw2AvbIIrBBCRxJOohBZZ08IYQ0knEQhN+Y7Sc1JCKEfCSdRiKnmdCw6idTMnGKvycjO5bMNp/lhVyRJ12WDQiGE5dnoXQBhXfzdHWng4cilxOscjEqkdzPvIte8tfI4P+yKAuDNP48zrJ0/o8KC6B5SD0VRqrvIQohaSGpOoojS+p1WHo4xB1NIfWcyc/JYceASY77eRb8PN/PvTWeITZKRfkKIypFwEkWY+51umu8UmZDGS8sPA/B4vyZseLYvKx7vyZiuQTjbGYlMSOeDv07S78NNHL6YWN3FFkLUIhJOogjTShEHohLJztU2H8zMyeXJHw+QkplDWLAnz97RHEVR6NjQk9kjQ9nzfwP54L5QWvq5kpGdx6frT+v5FoQQNZyEkyiimY8Lbg42pGflEh6TDMDsVSc4cikJDydbPhvTERtj4X86TnY23B8WxLyHOqMosOFEHKcvp+hRfCFELSDhJIowGG5sPrjn/DX+OhbLop3nAfh4VHsCPBxLfG5jb2cGtfYF4Kut56q8rEKI2knCSRTLtM7eysPRPL/sEABT+jTm9pa+t3zuY32bAPDbwUtclmWQhBAVoHs4zZ07l8aNG+Pg4EDnzp3Ztm1biddu3rwZRVGKHCdOnKjGEtcNpn6n/VGJJGfk0CHIgxeGtCzTczs19KRLI0+yc1UW7IioymIKIWopXcNp6dKlTJ8+nZkzZ3LgwAH69OnD0KFDiYqKKvV5J0+eJCYmxnw0a9asmkpcd7Rr4I5dfr+Sm4MNn4/piK2x7P9cHr1Nqz39uCuKlAyZqCuEKB9dw+njjz9m0qRJTJ48mVatWjFnzhyCgoKYN29eqc/z8fHBz8/PfBiNxmoqcd3hYGvktub1MSjwwf3tCarnVK7nD2jpQ5P6zqRk5rBk94UqKqUQorbSLZyysrLYt28fgwYNKnR+0KBB7Ny5s9TnduzYEX9/fwYMGMCmTZtKvTYzM5Pk5ORChyibz8d0ZOsL/Rncxq/czzUYFB69LQSA+dsjyMrJs3TxhBC1mG7hFB8fT25uLr6+hTvYfX19iY2NLfY5/v7+fPXVVyxfvpxff/2VFi1aMGDAALZu3Vri68yePRt3d3fzERQUZNH3UZs52hkJ9CxfjamgER0bUN/VntjkDP57KNqCJRNC1Ha6D4i4eS02VVVLXJ+tRYsWTJkyhU6dOtGjRw/mzp3L8OHD+fDDD0u8/4wZM0hKSjIfFy5IE1N1sbcxMrFnI0AbVq6qqr4FEkLUGLqFk7e3N0ajsUgtKS4urkhtqjTdu3fn9OmSVyOwt7fHzc2t0CGqz0PdgnG2M3LycgqbT13RuzhCiBpCt3Cys7Ojc+fOrFu3rtD5devW0bNnzzLf58CBA/j7+1u6eMJC3J1seaBrQwC+2iKTcoUQZaPrlhnPPvss48aNIywsjB49evDVV18RFRXF1KlTAa1J7tKlS3z33XcAzJkzh0aNGtGmTRuysrL44YcfWL58OcuXL9fzbYhbeKR3YxbtPM/f5xI4cjGJdoHuehdJCGHldA2n0aNHk5CQwKxZs4iJiaFt27asWrWK4OBgAGJiYgrNecrKyuK5557j0qVLODo60qZNG1auXMmwYcP0eguiDBp4OPKP9gGsOHCJzzee5j/jOsu+T0KIUilqHeulTk5Oxt3dnaSkJOl/qkbhMckM+2wbqgrPD27BE/2b6l0kIYQOyvodrPtoPVE3tPJ347U7WwPwwV8n+e3AJZ1LJISwZhJOotpM7NWYyb0bA/D8L4fYeTZe5xIJIayVhJOoVi8Pa8Wwdn5k56o89v0+TsmeT0KIYkg4iWplMCh8PKoDYcGepGTkMHHBbtlWQwhRhISTqHYOtka+Hh9GSH1nopMyeHjhHlIzc/QulhDCikg4CV14OtuxaGJXvF3sOB6TzOOL95OdK4vDCiE0Ek5CNw29nJg/oQuOtka2nrrCsr0X9S6SEMJKSDgJXbUP8uCpAdqcp9VHY3QujRDCWkg4Cd0Nbautjfj32QSS0mXXXCGEhJOwAo29nWnu60JOnsqmk3F6F0cIYQUknIRVGNRa2233r2PFbzQphKhbJJyEVTBtBb/l1BUysnN1Lo0QQm8STsIqtG3gRoC7A+lZuWw/LcsaCVHXSTgJq6AoCoPya09rj1e8aS82KYO1x2LZeuoKmTlSAxOiptJ1PychChrUxpdFO8+zPjyOnNw8bIyl/7dTckY2Ry4mcfBCIocuJHLoYiKXkzPNj7va29C/pQ+D2/jRr0V9nO3ln7sQNYX8v1VYja6N6uHhZMvVtCz2RV6jW4hXidcu33eRF5cfJiev8HZkBgWa+7pyNS2LuJRM/jgUzR+HorGzMdCnqTeD2/oxokMD7Gyk0UAIaybhJKyGjdHAgJa+LN9/kb+OXS4xnOJTM3n9j2Pk5Kk08HCkQ0MPOgR60KGhB20C3HCysyEvT+XgxUT+OhrLX8diOZ+QzoYTcWw4EcfFa9d59o7m1fzuhBDlIeEkrMqgNlo4rT0eyyt3tip2O/eP150iJTOHtg3c+OOJ3hgMRa8xGBQ6NfSkU0NPXhraklOXU/lq6zmW77/Inoir1fFWhBCVIG0bwqrc1qw+DrYGLl67zvGY5CKPh8cks2R3FACv3tmm2GC6maIotPBzZVL+RodHLyWRd1NzoBDCukg4CaviaGfktmb1AVh77HKhx1RV5c0/j5OnwvB2/nRtXK9c927m64K9jYGUzBzOJ6RZrMxCCMuTcBJWxzQh9+bVItYdv8zOswnY2Rh4aWjLct/X1migdYAbAEcuJVW6nNm5eWTlyDYfQlQFCSdhdQa08sFoUDgRm0JUQjoAmTm5vL0qHIApfRoTVM+pQvcObeAOwOGLlQsnVVWZsGA3PWZvIDE9q1L3EkIUJeEkrI6Hkx3d8pvsTBNyv915nsiEdOq72jOtX9MK37tdoAcARyoZTqfjUtl5NoGEtCz2R12r1L2EEEVJOAmrNKi1L6D1O8WnZvL5hjMAPD+4BS6VmEwbGqjVnI5GJ5FbiUERKw/f2HsqPCalwvcRQhRPwklYJdNSRnsir/J/K46ah47f1ymwUvdtUt8FR1sj6Vm5nLuSWuH7FNwYMbyYUYVCiMqRcBJWKcDDkXYN3FFVWJM/MKKsQ8dLYzQotG2gDYqoaL/TmbgUTl2+EWwSTkJYnoSTsFqD2/iaf6/I0PGStGvgAVR8xN6qI1pYmkIuIj5NtvkQwsIknITVGtJWa9qr6NDxkpj6nQ5fTKzQ81cd0Zr0xvdohJezHXkqnLpc8/uddp6NZ+w3u4iIlzlgQn8STsJqNfVxZf6EMH6a0q3CQ8eL0y4/nI5FJ5OTW755SueupHIiNgUbg8Kg1r609HcF4EQtGBSxcMd5dpxJ4PONp/UuihASTsK6DWjlS+dgyzTnmTT2csbV3obMnDxOx5VvUMTqo1qTXs+m3ng42dHKT2vaK26ppZrmfH6N6a+jsVzPkmZKoS8JJ1HnGAwKbfMn45Z3vpNpCPnwdlqTY0t/LZxOxNbscMrLU4m8qk14TsvKZX345Vs8Q4iqJeEk6iRzv9OlxDI/53x8GsdjkjEaFO5orYVTq/xmvfCYFFS15i4mG510vdBSTL8duKRjaYSQcBJ1lKnfqTw1p1X5c5t6NvGinrMdAE19XLAxKCRdzyY2OcPyBa0m5+O1WpOrgzbBecupK1xNk2WZhH4knESdFJo/nDw8JqXMi7euzh9CPrStv/mcvY2RJvVd8u9Vc5v2IuK1vreujerRtoEbOXkqK4/E3OJZQlQdCSdRJwXVc8Td0Zas3LwyDQOPSkjnyKUkDIq2IWJBLQs07dVUEfk1p8bezozo0ACQpj2hLwknUScpilJgvtOtm/ZMyxV1D/HC28W+0GOt8gdF1OSak2l/q0beztzVPgBFgX2R17iQP0hCiOom4STqrHamEXtlGBRhmng7tJ1/kcda+uXPdYqtuTUn0zDyxt7O+Lo50LOJFwC/H5Tak9CHhJOos8pac7p4LZ1DF5NQFBiSvyBtQaaa07krqTVyGaOc3Dyi8mtIjbydAcxNeysOXKrRoxBFzSXhJOos095OJ2NTSg2VNfkTb7s2qkd9V/sij/u42lMvfxmj05crvtK5Xi4lXicnT8XexoC/mwOgLR1lb2Pg7JU0jkXX3OZKUXNJOIk6K8DdAS9nO3Ly1FKb5Eyj1oaHFm3SA63/ytS0d6t+p5krjtDr3Y2crcR2HZZmWksv2MvJvOq7q4MtA1tpAz9kYITQg4STqLMURSkw3ymx2GuiE69zICoRRYHBxTTpmZgHRZSyUsTl5Ax+2h3FpcTrPPXjATJzrKMJ0BROjbycC52/u0MAAH8ciq7UxoxCVISEk6jTQhuU3O+kqiofrj0JQFiwJ775TV7FKUvN6feDlzB9xx+PSeaDNScrWmyLMg+GqF84nPq18MHDyZa4lEz+PpugR9FEHSbhJOo0U79TcXs7vbvmBL/uv4RBgSdvb1bqfVqZ19greRmjX/drzWOmQRXfbI9g88m4ihbdYiIS8uc43VRzsrMxMCx/dOJvMmpPVDMJJ1GnmUbsnbqcUmgl7q+2nuU/W84B8O7IUPo2r1/qfZr6uGA0KCSmF7+M0fHoZE7EpmBnNPDevaGM7xEMwHPLDnElJdNSb6dCTDUn00i9gkyj9tYcjS120Ehiehb7Iq9Ks5+wOAknUaf5ujng42pPngrHY7Ta0/J9F3ln1QkAXhzSklFdgm55HwdbI03ym8WK29tpxYGLAAxo5YO7ky0vD2tFC19X4lOzeG7ZIfJ0+nLPysnj4rUbq0PcLCzYkwYejqRm5rA+/DJZOXnsOpfAh3+d5O5/76DTm+u4d97fPPb93ho5jF5YLwknUecVnO+08cRlXlh+GIDJvRsztW9Ime/TsoS9nXJy8/jtYDQAIzsFAlqYff5gR+xtDGw5dYUFOyIq/T4q4sK1dPJUcLIz4lPMMHmDQTEPjHj9j+N0mLWWB77axRebznDoQiJ5KhgUWB8exyOL9pCWmVPdb0HUUhJOos5rl78I7K/7L/H44v3k5qmM7NiAl4e1QlGUMt+nYL9TQdvPxHMlJRNPJ9tCzYPNfV35vztbA/DemhMcLabfq6pFXDENI3cu8b2O6Kg17cWnZpKelYu3ix13dwjgg/tC+XvG7fw4pTvOdkZ2nk3gofn/Iyk9u9rKL2ovG70LIITeTDUn06CI/i3q8959oeY5P2V1YwHYwjWnFfnzhP7RPgA7m8L/PfhQt4ZsO3WFtccv8/SSA/z5VG+c7Krv/5amNfUaezuVeE1zX1c+G9ORy0kZ9GrqTUs/10Kfjb+7I4undGfCgt0ciEpk9Fd/8/2kbsVOWBairCScRJ1n2hUXoFNDD+aO7YytsfyNCq1vWsbIwdZIamYOfx3TVpi4J79JryBFUXjv3lAOX9zGuStphL21Hmd7GxxtjTjaGnGwM+Joa6CBhxNvjmhj8eCKKLCmXmn+0T6g1Mc7BHmw9LHuPPTNbk7EpjD6P3/z/eRuNPBwtFhZRd0izXqizqvvas8DXYLo08ybBRO74GhnrNB9fFzt8XSyJU+FM3HaChCrj8SQkZ1HSH1n2ge6F/s8T2c75jzQAVcHG9KzcrmSkknU1XROXk7h0IVEdp27yvL9F801MEsyr0buVXo4lUVLPzeWTe1BAw9HzsWnMerLv83hJ0R5Sc1JCODde0MrfQ9FUWjl78bOswkcj0mmbQN389ymezsFltp/1T3Ei10zBnAlJZPr2bmkZ+WSkf9zzdFYlu+/yJaTVxjbLbhMZTkZm8LKw9E83r8pDrYlh+35+JJH6lVEY29nfp7ag4e++R8R8WmM/s/f/Pp4TwI9S242FKI4UnMSwoJMI/ZOxKRwKfE6f5/TVlYwjXgrjbO9DY28nWnl70bnYE96NfXmjta+TOzZCIAdZ+LLvGvvjF8P89nGM3z/d2SJ12Rk5xKddB0ofo5TRTXwcOTnx3rQ3NeFuJRMHlm0h+QMGSQhykfCSQgLalVgUIRpwdTuIfUqVXNoE+CGt4sdaVm57I28esvr45Iz2B+VCMC68MslXhd1NR1VBVd7G7yc7SpcvuLUd7Vn0cNd8XG159TlVKb9sK/MwSoESDgJYVEFF4D9db828XZkx6IDIcrDYFC4rZk2BH3LqSu3vL5gIO2LvEZielax1527cmNliPIMmS+rAA9HFkzsgpOdkR1nEpi54ojsDSXKTMJJCAsquIzR2Stp2NsYGNqu5NXMy6pvi/xwOnnrcFp77EY45eapJQZawa3Zq0rbBu588WBHDAos23eRf286U2WvJWoXCSchLMjB1khIgS/7QW38cHWwrfR9b2tWH0XRJvjG5PcTFSclI9u8gvig1tp+TOvDi19c9nwZh5FX1u0tfXnjH20A+HDtKdn6XZSJhJMQFmZq2gMY2amBRe7p6WxH+/wV1LeW0rS35dQVsnLzCPF25rH8pZc2n4wjO7dof8+NOU5VP5JuXI9GTOnTGIDnlx1md8St+85E3aZ7OM2dO5fGjRvj4OBA586d2bZtW5met2PHDmxsbOjQoUPVFlCIcjKtFOHtYk+fpt4Wu2+//Ka9zaU07Zma9O5o40uHIE/qOduRkpHD3vPXilxryTlOZTFjaCuGtvUjKzePKd/t5ZwV7QYsrI+u4bR06VKmT5/OzJkzOXDgAH369GHo0KFERUWV+rykpCTGjx/PgAEDqqmkQpTdXaEBtPRz5fnBzbGpwEoTJTGty7f9dHyxNaGsnDw2ndCa8Aa19sNoUOjfwgeADTeN2kvPyuFysrZVR1U365kYDAqfjO5AhyAPkq5n89bK8Gp5XVEz6RpOH3/8MZMmTWLy5Mm0atWKOXPmEBQUxLx580p93mOPPcaDDz5Ijx49qqmkQpRdUD0n1ky/jdFdGlr0vqGBHng62ZKSmcOB/KHiBe06l0BKZg7eLvZ0DPIAYGCr/HA6UbjfyTT51sPJFg8nyw4jL42DrZFPRndAUWDjiTjzShrWIjs3j7dXHmeTFWwCWdfpFk5ZWVns27ePQYMGFTo/aNAgdu7cWeLzFi5cyNmzZ3nttdfK9DqZmZkkJycXOoSoiYwGhduam5r2in55rj2ureF3R2sf88KsvZt5Y2tUiIhPK9SMZupvqq4mvYIaezszsJU2WGP+dn22CinJhvA4vt4WwfPLDskGijrTLZzi4+PJzc3F19e30HlfX19iY2OLfc7p06d56aWXWLx4MTY2ZVt5afbs2bi7u5uPoKBbbxwnhLUyNe3dPDw8L09l/fEbTXomrg62dA/xArQvXhNTf1NINTXp3Wxyb21wxK/7L5KQqu9OwAUdj9ZWpo9PzeLghaL9dKL66D4g4ubJf6qqFjshMDc3lwcffJA33niD5s2bl/n+M2bMICkpyXxcuHCh0mUWQi+mmtOx6GTiUm5sB3/kUhKxyRk42xnp0cSr0HNub6k17a0v0O8UUcrW7NWha+N6hAa6k5mTxw+7Su9jrk4FN4osOF9MVD/dwsnb2xuj0ViklhQXF1ekNgWQkpLC3r17efLJJ7GxscHGxoZZs2Zx6NAhbGxs2LhxY7GvY29vj5ubW6FDiJrK28XevP9UwQm5pia9fi18iiz0ampC2xt5zbwR4Hmdw0lRFCb30Ya6f7/rvNVs8R4ec2OjyLXHL1tkRQtZtqlidAsnOzs7OnfuzLp16wqdX7duHT179ixyvZubG0eOHOHgwYPmY+rUqbRo0YKDBw/SrVu36iq6ELoqrmnP9F/5g9oU/Q+7oHpONPd1ITdPZfMprWnPvMmgDn1OJkPb+hHg7kB8apZVTMxNTM/iUqI2wdnUT3e2ksPdP99wmtavruGTdafIkz6sctG1We/ZZ5/lm2++YcGCBYSHh/PMM88QFRXF1KlTAa1Jbvz48VpBDQbatm1b6PDx8cHBwYG2bdvi7Kzf/8mEqE6m+U7bTseTk5tHRHwap+NSsTEo9MsfOn6z21tqobUhPI6UjGziU7X19hpVwwTcktgaDTzcS+t7+mZbhO7r7plqTYGejvTKn5/2VyWa9rJy8li48zw5eSqfbjjNxEV7uJpW/DqHoihdw2n06NHMmTOHWbNm0aFDB7Zu3cqqVasIDtb2rImJibnlnCch6pr2gR64OdiQdD2bQxcTWZffpNejiRfujsUvlWQaUr755I3h294udhZZWqkyRncNwsXehtNxqWVa1LYqmfqbWvu7mQeVrD1e8XDacuoKV9OycHWwwd7GwNZTV7jr8+0cupBoieLWeroPiHj88cc5f/48mZmZ7Nu3j9tuu8382KJFi9i8eXOJz3399dc5ePBg1RdSCCtiYzTQp/mNhWDNTXqtizbpmXRs6Imnky3JGTn8sk9bLV2PYeQ3c3OwZXQXbQTtN9v0HVYenh9OrfzdGNjaB0WBQxcSiU3KuMUzi2dalf6BLkH89kQvGnk5cSnxOvd/+Tff74rUvaZo7XQPJyFE+fXLD6ffD0WzL0ob8jywlHAquFrE8vwvzepaGeJWJvZshEGB7WfiOR5d8jzEKymZVfqFbnrt1gFu+Lg6mCcyl7YnVkkS07PMQ/dHdgqklb8bfzzVm8FtfMnKzeOV347y7M+HSM/KsVj5axsJJyFqINOgiMgEbcPA0EB3/N0dS33OgPxRexnZ2ugxvUbq3SyonhND2/kDxU/K3XUugTFf7aLL2+t57Y9jVVKGrJw8c3Nn6/yFewe1yW/aO1b8vMvS/PdwDFm5ebTydzMvBOzmYMuXD3Vm5rBWGA0KKw5cYuKCPVKDKoGEkxA1kI+bg/lLFEpv0jO5rbk3NoYbcwitpeYEMCV/WPkfhy5xOTkDVVXZcSaeUf/5mwe+2mXe7v77XZEcuZhk8dc/eyWVrNw8XB1sCPTUQt70mf59NoGk6+XbZt7UpHfvTavSK4rClNtC+HFyNxxsDew+f5VDVfB+agMJJyFqKNOoPbjxX/mlcXWwpVtIPfPf1tDnZNIhyIOwYE+yc1Xe+O8x7v/yb8Z+8z92R1zFzmhgXPdg7mjti6rCm38et3htw9Sk18rfzbwIQEh9F5r6uJCTpxa7XFRJzl1J5UBUIkaDwj86BBR7TbcQL4a21WqLv+yThQGKI+EkRA11R/5/2Tf3daGZj0uZnjOg5Y0alp7DyItjmpS76kgseyOvYW9jYGLPRmx9oT9vjmjLG/9oY65trDla/qa20oQXGKlXkKn2VJ5ReysOaHO2bmvmjY+rQ4nX3dc5EIA/DkZbzSRkayLhJEQN1bGhJ0se7c6CiV2KXfKrOIPb+uFsZyQ00B0nu7KtT1ld7mjtS/sgDxxsDUzq3ZhtL/Tn9X+0wc9d+4IP8HDk0fwAe2d1uEW/0I+XFE75NdLNJ+LIzLn16+Xlqfy6XwunkZ0CS722R4gXAe4OJGfkFFpaSmgknISowbqHeBHoWfYaUAMPR9Y+25fvHulahaWqGKNB4ZepPTj82mBeubM1Pm5Fax2P9W2Cr5s9F65eZ9HO8xZ5XVVVCw0jLyi0gTu+bvakZeWy82zCLe/1v4irXEq8jqu9jblmWxKDQeHe/NrTsr0XK1j62kvCSYg6poGHY7Xu4VQetkYDdjYlfy0529vwwuCWAHyx8QxXUkpe0XzHmXiGfrqN7/8+X+prxiZncC09G6NBoZlv4eZRg0Exh0xZFoI1DYQYHupfZI3D4tybX7vadvpKhedT1VYSTkKIGuWejg0IDXQnNTOHj9edLPK4qqp8vfUc4+b/j/CYZD7dcJqcYnYONjHVmprUdy42UEyrRaw7frnU9fGuZ+Wy6kgMcOsmPZNG3s50bVSPPPVGX5XQSDgJIWoUg0HhlTtbA7B0z4VCE3evZ+XyzyUHeXtVOHkqGBRtb6bdEVdLvJ958q1/8TsWdA/xwtXehvjUTA6UsvTQ2uOxpGXlElTPkS6NPMv8fkwDI37Zd0HmPBUg4SSEqHG6NKrH8FB/8lR4a6U2tPzC1XRGztvJH4eisTEovPGPNtzfWVsa6c/8Gk1xTAu+3tzfZGJnY6B//p5Ypq1JirPcNBCiY2CZB6gADAv1x9HWyNkraRyUdffMJJyEEDXSS0NaYmdjYOfZBN7/6yR3fbGd8JhkvF3sWDy5GxN6NuLO9tpcojVHY0ts2jOP1Asoea8301Yka48Vv8fT5eQMtp/WFq4dedPE21txsbdhaFut6dC07qGQcBJC1FBB9ZzM273P23yWxPRs2ge688eTvemWvzV9jxAv6jnbcTUty7zKREFpmTnmva1KqjmBtlyUndFARHwab/z3OKuPxHA5+cYAht8OXCJPhbBgT4IrMLnZPOfpkMx5MpFwEkLUWI/3b4qPqz0A93cOZOljPQjwuLHGoI3RwJD8WsnKw0Wb9k7EpqCq4ONqj7eLfYmv4+pga16RY9HO80xbvJ9u72yg17sbefLH/Xy/KxIo+0CIm3UP8aKBhyMpGTmV2qajNpFwEkLUWC72Nvz2RC9+fqwH798XWuxouzvzF5VdcyyW7Jua9sLL0KRn8tGo9nx4f3se7NaQln6uGBS4lHidPw/HcPHadexsDAwP9a/Q+zAYFPM6fNK0p7GuKeJCCFFOAR6OhWpLN+vauB7eLnbEp2ax82yCeUV3uNHfVFqTnomrgy33dQ40N8GlZuZw+EIi+6OuceRSEv1b+JS42WNZ3Ns5kM82nmF7/pwn08oYdZXUnIQQtVrhpr3oQo+VtKZeWbjY29CzqTdP3t6M/4wL44GuDStVzmCvG3Oefj0gtScJJyFErXdnqLY6+JqjsWTlaE17uXkqJ24xjLy63ZjzdLFcc542n4yj2zvrWVeL+qsknIQQtV6XRvWo72pPckYOO87EA3A+IY3r2bk42BqsZm8r05ync1fS2B+VWKbnqKrK7FUnuJycyacbTlVtAYETscnVMllYwkkIUesZDQrD8pv2/swftWdq0mvh54bRUPZJs1XJxd6Goe20ci7YUXRX4OJsPR3PyctaDfDopWTz+6oKm0/Gcdfn23nl96OlLuVkCRJOQog6YXh+097a47Fk5uTectkivUwx72sVw6n80CnN11vPAZh3OV5eRaP9dp1L4LHv95Gdq3ItLZu8Kq49STgJIeqEsGBPfFztScnIYfvp+AKDIVx1LllhrfzdGNLGD1WFzzacLvXa49HJbD8Tj0HBvN7gbwcvFRkyX1kHLyQyadEeMnPyuL2lD5+M7oCNsWrjQ8JJCFEnGAwKw/LnPK08HFOmZYv08vSAZgCsPBLD6VJqT99s02pNw9r582C3hni72BOfmsXmk1csVpbj0cmMn/8/0rJy6dnEi7ljO5W6rYmlSDgJIeqMu/LX2lt1NIbLydpeUC38rC+cWge4MbiNL6oKn288U+w1MUnX+eOQNjR+Sp8QbI0G7umoNV3+su+CRcpxJi6VcfP/R3JGDp2DPfl6fFiZ9qmyBAknIUSd0THIE393BzKytWavRl5OuNhb51oEptrTfw9HcyauaO1p0c7z5OSpdG1cj/ZBHgDcl78K+4bwOBJSS96IsSyiEtIZ+80uEtKyaNvAjQUTu+BcjZ+VhJMQos4o2LQH1jO/qThtAtwZ1Lr42lNqZg4//i8KgEfzB1AAtPBzJTTQnZw8ld8PFp5wXB4xSdd58JtdXE7OpLmvC9890q1Sq19UhISTEKJOKbj+nbWN1LuZqfb0x6FozsSlms8v3XOBlIwcQuo7c3v+XlMmpom8yyo4ak9VVaZ8t5eL167TyMuJHyZ1o56zXQXfQcVJOAkh6pSOQR40yF+Lr12gu86lKV3bBu7ckV97+mKjNnIvJzePBdu1OVCTe4dguGmO1j/aB2BnNBAek8yx6KRyv+aOMwkcvZSMs52RHyZ3w8dNnzX+JJyEEHWKoih8+VBnZt3dptAisNbqnwVqT2evpLL6aCyXEq/j5WxX7MaGHk523NFa2xyxIiucL9p5HtAWog30dKp4wStJwkkIUee0C3RnfI9G5dpOXS9tG7gzsJUPeSp8sfEMX+cPHx/XI7jEkXOmpr3fD0ab1xIsiwtX09lwQlufb3yPRpUreCVJOAkhhJX754DmAKw4cInDF5OwtzEwrntwidf3aeaNj6s9V9Oy2Hgirsyv8/2uSFRVe35TH5dKl7syJJyEEMLKtQt0Z0CBgQ/3dg7Eq5Sde22MBu4p5+aF6Vk5LNmtjQCc2LNRxQtrIRJOQghRA/xzoNb3pCgwqXfjW15/X/6W8ZtOxnEl5dZznn47EE1yRg4N6znRr4XPLa+vahJOQghRA4QGevD5mI7MfbATTerfusmtma8r7YM8yM1T+f3gpVKvVVWVb/MHQozvEWwVq7RLOAkhRA1xV/sAhhaYRHwr95vmPO29WOoWF7vOXeXk5RQcbY3cHxZU6XJagoSTEELUUneFBuBga+Dk5RTe+O+xEjcJNNWa7unUoNpXgiiJhJMQQtRS7k62vHNPOwC+/TuSd1efKBJQF6+ls/Z4LAATdB4+XpCEkxBC1GIjOwXy9j1tAfjP1nN8etMeUT/siiJPhZ5NvGjhZz17W0k4CSFELTe2W7B5M8I560/zny1nAcjIzmXJHm34+AQrGD5ekHWuFS+EEMKiJvVuTEZ2Lh/8dZLZq0/gaGfEwcZIYno2DTwcGdjKV+8iFiLhJIQQdcQT/ZuSkZ3L5xvP8Orvx/DKX218nJUMHy9ImvWEEKIOefaO5kzOn8SbkJaFvY2B0VYyfLwgCSchhKhDFEVh5vBWPNS9IQCjuwThqcN+TbcizXpCCFHHKIrCm3e35aHuwYR467vAa0kknIQQog5SFIWWfta7E7A06wkhhLA6Ek5CCCGsjoSTEEIIqyPhJIQQwupIOAkhhLA6Ek5CCCGsjoSTEEIIqyPhJIQQwupIOAkhhLA6Ek5CCCGsjoSTEEIIqyPhJIQQwupIOAkhhLA6Ek5CCCGsTp3bMkNVVQCSk5N1LokQQtQ9pu9e03dxSepcOKWkpAAQFGR92xILIURdkZKSgru7e4mPK+qt4quWycvLIzo6GldXVxRFKffzk5OTCQoK4sKFC7i5We9GXVVNPgf5DEA+AxP5HMr+GaiqSkpKCgEBARgMJfcs1bmak8FgIDAwsNL3cXNzq7P/CAuSz0E+A5DPwEQ+h7J9BqXVmExkQIQQQgirI+EkhBDC6kg4lZO9vT2vvfYa9vb2ehdFV/I5yGcA8hmYyOdg+c+gzg2IEEIIYf2k5iSEEMLqSDgJIYSwOhJOQgghrI6EkxBCCKsj4VROc+fOpXHjxjg4ONC5c2e2bdumd5GqzNatW7nrrrsICAhAURR+++23Qo+rqsrrr79OQEAAjo6O9OvXj2PHjulT2Coye/ZsunTpgqurKz4+PowYMYKTJ08WuqYufA7z5s0jNDTUPMGyR48erF692vx4XfgMbjZ79mwURWH69Onmc7X9c3j99ddRFKXQ4efnZ37cku9fwqkcli5dyvTp05k5cyYHDhygT58+DB06lKioKL2LViXS0tJo3749X3zxRbGPv//++3z88cd88cUX7NmzBz8/P+644w7z+oW1wZYtW3jiiSfYtWsX69atIycnh0GDBpGWlma+pi58DoGBgbz77rvs3buXvXv3cvvtt3P33Xebv3jqwmdQ0J49e/jqq68IDQ0tdL4ufA5t2rQhJibGfBw5csT8mEXfvyrKrGvXrurUqVMLnWvZsqX60ksv6VSi6gOoK1asMP+dl5en+vn5qe+++675XEZGhuru7q5++eWXOpSwesTFxamAumXLFlVV6+7noKqq6unpqX7zzTd17jNISUlRmzVrpq5bt07t27ev+s9//lNV1brxb+G1115T27dvX+xjln7/UnMqo6ysLPbt28egQYMKnR80aBA7d+7UqVT6iYiIIDY2ttDnYW9vT9++fWv155GUlARAvXr1gLr5OeTm5rJkyRLS0tLo0aNHnfsMnnjiCYYPH87AgQMLna8rn8Pp06cJCAigcePGPPDAA5w7dw6w/Puvcwu/VlR8fDy5ubn4+voWOu/r60tsbKxOpdKP6T0X93lERkbqUaQqp6oqzz77LL1796Zt27ZA3focjhw5Qo8ePcjIyMDFxYUVK1bQunVr8xdPXfgMlixZwv79+9mzZ0+Rx+rCv4Vu3brx3Xff0bx5cy5fvsxbb71Fz549OXbsmMXfv4RTOd28zYaqqhXaeqO2qEufx5NPPsnhw4fZvn17kcfqwufQokULDh48SGJiIsuXL2fChAls2bLF/Hht/wwuXLjAP//5T9auXYuDg0OJ19Xmz2Ho0KHm39u1a0ePHj1o0qQJ3377Ld27dwcs9/6lWa+MvL29MRqNRWpJcXFxRf5LoS4wjdCpK5/HU089xR9//MGmTZsKbblSlz4HOzs7mjZtSlhYGLNnz6Z9+/Z8+umndeYz2LdvH3FxcXTu3BkbGxtsbGzYsmULn332GTY2Nub3Wts/h4KcnZ1p164dp0+ftvi/AwmnMrKzs6Nz586sW7eu0Pl169bRs2dPnUqln8aNG+Pn51fo88jKymLLli216vNQVZUnn3ySX3/9lY0bN9K4ceNCj9eVz6E4qqqSmZlZZz6DAQMGcOTIEQ4ePGg+wsLCGDt2LAcPHiQkJKROfA4FZWZmEh4ejr+/v+X/HZR7CEUdtmTJEtXW1ladP3++evz4cXX69Omqs7Ozev78eb2LViVSUlLUAwcOqAcOHFAB9eOPP1YPHDigRkZGqqqqqu+++67q7u6u/vrrr+qRI0fUMWPGqP7+/mpycrLOJbecadOmqe7u7urmzZvVmJgY85Genm6+pi58DjNmzFC3bt2qRkREqIcPH1Zffvll1WAwqGvXrlVVtW58BsUpOFpPVWv/5/Cvf/1L3bx5s3ru3Dl1165d6p133qm6urqavwMt+f4lnMrp3//+txocHKza2dmpnTp1Mg8pro02bdqkAkWOCRMmqKqqDR197bXXVD8/P9Xe3l697bbb1CNHjuhbaAsr7v0D6sKFC83X1IXP4ZFHHjH/u69fv746YMAAczCpat34DIpzczjV9s9h9OjRqr+/v2pra6sGBASoI0eOVI8dO2Z+3JLvX7bMEEIIYXWkz0kIIYTVkXASQghhdSSchBBCWB0JJyGEEFZHwkkIIYTVkXASQghhdSSchBBCWB0JJyGEEFZHwkmIOkJRFH777Te9iyFEmUg4CVENJk6ciKIoRY4hQ4boXTQhrJLs5yRENRkyZAgLFy4sdM7e3l6n0ghh3aTmJEQ1sbe3x8/Pr9Dh6ekJaE1u8+bNY+jQoTg6OtK4cWOWLVtW6PlHjhzh9ttvx9HRES8vLx599FFSU1MLXbNgwQLatGmDvb09/v7+PPnkk4Uej4+P55577sHJyYlmzZrxxx9/VO2bFqKCJJyEsBKvvPIK9957L4cOHeKhhx5izJgxhIeHA5Cens6QIUPw9PRkz549LFu2jPXr1xcKn3nz5vHEE0/w6KOPcuTIEf744w+aNm1a6DXeeOMNRo0axeHDhxk2bBhjx47l6tWr1fo+hSgTyyykLoQozYQJE1Sj0ag6OzsXOmbNmqWqqrY1x9SpUws9p1u3buq0adNUVVXVr776SvX09FRTU1PNj69cuVI1GAxqbGysqqqqGhAQoM6cObPEMgDq//3f/5n/Tk1NVRVFUVevXm2x9ymEpUifkxDVpH///sybN6/QuXr16pl/79GjR6HHevTowcGDBwEIDw+nffv2ODs7mx/v1asXeXl5nDx5EkVRiI6OZsCAAaWWITQ01Py7s7Mzrq6uxMXFVfQtCVFlJJyEqCbOzs5FmtluRVEUQNsS3fR7cdc4OjqW6X62trZFnpuXl1euMglRHaTPSQgrsWvXriJ/t2zZEoDWrVtz8OBB0tLSzI/v2LEDg8FA8+bNcXV1pVGjRmzYsKFayyxEVZGakxDVJDMzk9jY2ELnbGxs8Pb2BmDZsmWEhYXRu3dvFi9ezO7du5k/fz4AY8eO5bXXXmPChAm8/vrrXLlyhaeeeopx48bh6+sLwOuvv87UqVPx8fFh6NChpKSksGPHDp566qnqfaNCWICEkxDVZM2aNfj7+xc616JFC06cOAFoI+mWLFnC448/jp+fH4sXL6Z169YAODk58ddff/HPf/6TLl264OTkxL333svHH39svteECRPIyMjgk08+4bnnnsPb25v77ruv+t6gEBakqKqq6l0IIeo6RVFYsWIFI0aM0LsoQlgF6XMSQghhdSSchBBCWB3pcxLCCkjruhCFSc1JCCGE1ZFwEkIIYXUknIQQQlgdCSchhBBWR8JJCCGE1ZFwEkIIYXUknIQQQlgdCSchhBBW5/8BfoWAc6RUrlYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'history' is from your model.fit()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot of Model Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
